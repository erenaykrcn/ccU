{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07f6013b-e239-406e-8e34-8f81eb70fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.linalg import expm\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def bonds_from_perms(perms):\n",
    "    \"\"\"\n",
    "    Each row p in perms encodes pairs:\n",
    "    (p[0], p[1]), (p[2], p[3]), ...\n",
    "    \"\"\"\n",
    "    bonds = []\n",
    "    for p in perms:\n",
    "        assert len(p) % 2 == 0\n",
    "        for k in range(0, len(p), 2):\n",
    "            bonds.append((p[k], p[k+1]))\n",
    "    return bonds\n",
    "\n",
    "sx = sp.csr_matrix([[0, 1],\n",
    "                    [1, 0]], dtype=complex)\n",
    "\n",
    "sy = sp.csr_matrix([[0, -1j],\n",
    "                    [1j,  0]], dtype=complex)\n",
    "\n",
    "sz = sp.csr_matrix([[1,  0],\n",
    "                    [0, -1]], dtype=complex)\n",
    "\n",
    "id2 = sp.identity(2, dtype=complex, format='csr')\n",
    "\n",
    "\n",
    "def two_site_pauli_term(L, i, j, pauli1, pauli2):\n",
    "    \"\"\"\n",
    "    Build the operator:\n",
    "        I ⊗ ... ⊗ pauli1(at i) ⊗ ... ⊗ pauli2(at j) ⊗ ... I\n",
    "    \"\"\"\n",
    "    if i == j:\n",
    "        raise ValueError(\"i and j must be different\")\n",
    "\n",
    "    if i > j:\n",
    "        i, j = j, i\n",
    "        pauli1, pauli2 = pauli2, pauli1\n",
    "\n",
    "    ops = []\n",
    "    for site in range(L):\n",
    "        if site == i:\n",
    "            ops.append(pauli1)\n",
    "        elif site == j:\n",
    "            ops.append(pauli2)\n",
    "        else:\n",
    "            ops.append(id2)\n",
    "\n",
    "    op = ops[0]\n",
    "    for k in range(1, L):\n",
    "        op = sp.kron(op, ops[k], format='csr')\n",
    "    return op\n",
    "\n",
    "\n",
    "def build_H(L, bonds, J, h, n_neighbours):\n",
    "    dim = 2**L\n",
    "    H = sp.csr_matrix((dim, dim), dtype=complex)\n",
    "    for (i, j) in bonds:\n",
    "        if J[0] != 0:\n",
    "            H += J[0] * two_site_pauli_term(L, i, j, sx, sx)\n",
    "        if J[1] != 0:\n",
    "            H += J[1] * two_site_pauli_term(L, i, j, sy, sy)\n",
    "        if J[2] != 0:\n",
    "            H += J[2] * two_site_pauli_term(L, i, j, sz, sz)\n",
    "\n",
    "        if h[0] != 0:\n",
    "            H += h[0]  * (two_site_pauli_term(L, i, j, sx, id2) + two_site_pauli_term(L, i, j, id2, sx))/n_neighbours\n",
    "        if h[1] != 0:\n",
    "            H += h[1]  * (two_site_pauli_term(L, i, j, sy, id2) + two_site_pauli_term(L, i, j, id2, sy))/n_neighbours\n",
    "        if h[2] != 0:\n",
    "            H += h[2]  * (two_site_pauli_term(L, i, j, sz, id2) + two_site_pauli_term(L, i, j, id2, sz))/n_neighbours\n",
    "    return H\n",
    "\n",
    "perms_1 = [[0, 4, 6, 10, 2, 5, 8, 11], [4, 6, 10, 0, 5, 8, 11, 2]]\n",
    "perms_2 = [[0, 1, 2, 3, 6, 7, 8, 9], [1, 2, 3, 0, 7, 8, 9, 6]]\n",
    "perms_3 = [[1, 4, 9, 11, 3, 5, 7, 10], [4, 1, 11, 9, 5, 7, 10, 3]]\n",
    "bonds_1 = bonds_from_perms(perms_1)\n",
    "bonds_2 = bonds_from_perms(perms_2)\n",
    "bonds_3 = bonds_from_perms(perms_3)\n",
    "all_bonds = bonds_1 + bonds_2 + bonds_3\n",
    "L = 12\n",
    "J = (1,  1, 1)\n",
    "h = (3, -1, 1)\n",
    "hamil = build_H(L, all_bonds, J, h, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "cc55e864-0eb1-4b41-aa0e-e69061eb9d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trotter error of the starting point:  0.002341196319632255\n",
      "Trotter error of the starting point:  0.0056217108298650675\n",
      "0.003981453574748661\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import sys\n",
    "import scipy\n",
    "\n",
    "t = 0.125\n",
    "sys.path.append(\"../../src/brickwall_sparse\")\n",
    "from utils_sparse import construct_ising_local_term, reduce_list, X, I2, get_perms, construct_heisenberg_local_term\n",
    "from ansatz_sparse import ansatz_sparse\n",
    "import rqcopt as oc\n",
    "from scipy.sparse.linalg import expm_multiply\n",
    "from qiskit.quantum_info import random_statevector\n",
    "from scipy.linalg import expm\n",
    "from qiskit.quantum_info import state_fidelity\n",
    "\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "Y = np.array([[0, -1j], [1j, 0]])\n",
    "YZ = np.kron(Y, Z)\n",
    "I2 = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "a_s = 27\n",
    "state = np.array(random_statevector(2**L).data)\n",
    "with h5py.File(f'./results/kagome_Heis_L12_t0.125_layers{a_s}.hdf5') as f:\n",
    "    Vlist  =  f[\"Vlist\"][:]\n",
    "\n",
    "if a_s == 45:\n",
    "    perms_extended = [[perms_1[0]]] + [perms_1] + [[perms_1[0]], [perms_2[0]]] +\\\n",
    "          [perms_2] + [[perms_2[0]], [perms_3[0]]] +  [perms_3] + [[perms_3[0]]]\n",
    "    perms_extended = perms_extended*5\n",
    "    perms_ext_reduced = [perms_1] + [perms_2] + [perms_3]\n",
    "    perms_ext_reduced = perms_ext_reduced*5\n",
    "    non_control_layers = [i for i in range(1, len(Vlist), 3)]\n",
    "    control_layers = []\n",
    "    for i in range(len(Vlist)):\n",
    "        if i not in non_control_layers:\n",
    "            control_layers.append(i)\n",
    "else:\n",
    "    perms_extended = [[perms_1[0]]] + [perms_1] + [[perms_1[0]], [perms_2[0]]] +\\\n",
    "          [perms_2] + [[perms_2[0]], [perms_3[0]]] +  [perms_3] + [[perms_3[0]]]\n",
    "    perms_extended = perms_extended*3\n",
    "    perms_ext_reduced = [perms_1] + [perms_2] + [perms_3]\n",
    "    perms_ext_reduced = perms_ext_reduced*3\n",
    "    non_control_layers = [i for i in range(1, len(Vlist_start), 3)]\n",
    "    control_layers = []\n",
    "    for i in range(len(Vlist_start)):\n",
    "        if i not in non_control_layers:\n",
    "            control_layers.append(i)\n",
    "\n",
    "Vlist_reduced = []\n",
    "for i in range(len(Vlist)):\n",
    "    if i not in control_layers:\n",
    "        Vlist_reduced.append(Vlist[i])\n",
    "\n",
    "print(\"Trotter error of the starting point: \", 1-state_fidelity(ansatz_sparse(Vlist, L, perms_extended, state), expm_multiply(\n",
    "    1j * t * hamil, state)))\n",
    "print(\"Trotter error of the starting point: \", 1-state_fidelity(ansatz_sparse(Vlist_reduced, L, perms_ext_reduced, state), expm_multiply(\n",
    "    -1j * t * hamil, state)))\n",
    "print((1-state_fidelity(ansatz_sparse(Vlist, L, perms_extended, state), expm_multiply(\n",
    "    1j * t * hamil, state)))/2 + (1-state_fidelity(ansatz_sparse(Vlist_reduced, L, perms_ext_reduced, state), expm_multiply(\n",
    "    -1j * t * hamil, state)))/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "135f2a39-3708-45dd-be57-115c900645ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005717953070153103\n",
      "0.009606542572692112\n",
      "0.007662247821422663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse as sp\n",
    "from utils_sparse import applyG_state\n",
    "\n",
    "ket_0 = np.array([1, 0])\n",
    "ket_1 = np.array([0, 1])\n",
    "sv = random_statevector(2**L).data\n",
    "state1 = np.kron(ket_0, sv)\n",
    "state2 = np.kron(ket_1, sv)\n",
    "\n",
    "for i in range(len(Vlist)):\n",
    "    if i in control_layers:\n",
    "        U1_est, U2_est, U_prod, U1, U2 = best_local_unitaries(Vlist[i])\n",
    "        Vlist_start[i] = [U1, U2]\n",
    "perms_qc = [[0, 1], [0, 2]]\n",
    "\n",
    "def apply(state):\n",
    "    count = 0\n",
    "    for i, V in enumerate(Vlist):\n",
    "        layer = i\n",
    "        if i in control_layers:\n",
    "            #Glist = Xlists_opt[i]\n",
    "            Glist = [make_controlled(P) for P in Vlist_start[i]]\n",
    "            for perm in perms_extended[i]:\n",
    "                for j in range(len(perm)//2):\n",
    "                    for _, G in enumerate(Glist):\n",
    "                        mapping = {0: 0, 1: perm[2*j]+1, 2: perm[2*j+1]+1}\n",
    "                        state = applyG_state(G, state, L+1, mapping[perms_qc[_][0]], mapping[perms_qc[_][1]])\n",
    "                        count += 1\n",
    "                \n",
    "        else:\n",
    "            for perm in perms_extended[layer]:\n",
    "                for j in range(len(perm)//2):\n",
    "                    state = applyG_state(V, state, L+1, perm[2*j]+1, perm[2*j+1]+1)\n",
    "                    count += 2\n",
    "                    \n",
    "    return state, count\n",
    "\n",
    "sv1, count = apply(state1)\n",
    "sv2, count1 = apply(state2)\n",
    "\n",
    "exact_v1 = np.kron(ket_0, expm_multiply(-1j * t * hamil, sv))\n",
    "exact_v2 = np.kron(ket_1, expm_multiply(1j * t * hamil, sv))\n",
    "\n",
    "print(1-state_fidelity(sv1, exact_v1))\n",
    "print(1-state_fidelity(sv2, exact_v2))\n",
    "print((1-state_fidelity(sv1, exact_v1) + 1-state_fidelity(sv2, exact_v2))/2)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "d62b37e1-0722-4806-886a-df1c73f7cb87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f:  -7.999999999999908\n",
      "Best err:  2.194623546888457e-07\n",
      "Best f:  -7.9999999999998\n",
      "Best err:  2.645070005744691e-07\n",
      "Best f:  -7.999999999999892\n",
      "Best err:  2.418418752404487e-07\n",
      "Best f:  -7.99999999999992\n",
      "Best err:  1.9193231805182194e-07\n",
      "Best f:  -7.999999999999954\n",
      "Best err:  1.6508455377810545e-07\n",
      "Best f:  -7.999999999999993\n",
      "Best err:  7.34147684591197e-08\n",
      "Best f:  -7.999999999999916\n",
      "Best err:  1.894973176760365e-07\n",
      "Best f:  -7.999999999999865\n",
      "Best err:  2.680090099821909e-07\n",
      "Best f:  -7.999999999999923\n",
      "Best err:  2.0431197869470742e-07\n",
      "Best f:  -7.99999999999992\n",
      "Best err:  2.2369530297767706e-07\n",
      "Best f:  -7.999999999999895\n",
      "Best err:  2.0012459633252874e-07\n",
      "Best f:  -7.999999999999925\n",
      "Best err:  1.7854531724017053e-07\n",
      "Best f:  -7.9999999999998455\n",
      "Best err:  2.983811331133999e-07\n",
      "Best f:  -7.999999999999742\n",
      "Best err:  3.819822139708825e-07\n",
      "Best f:  -7.999999999999871\n",
      "Best err:  2.3481195954943711e-07\n",
      "Best f:  -7.99999999999964\n",
      "Best err:  3.933209204882563e-07\n",
      "Best f:  -7.999999999999979\n",
      "Best err:  1.1599174978259067e-07\n",
      "Best f:  -7.999999999999919\n",
      "Best err:  2.1109267453193625e-07\n",
      "Best f:  -7.999999999999935\n",
      "Best err:  1.9161596179086937e-07\n",
      "Best f:  -7.99999999999991\n",
      "Best err:  2.1162433936457312e-07\n",
      "Best f:  -7.999999999999876\n",
      "Best err:  2.618016076576124e-07\n",
      "Best f:  -7.999999999999928\n",
      "Best err:  1.8027700983964407e-07\n",
      "Best f:  -7.999999999999786\n",
      "Best err:  2.844736542574798e-07\n",
      "Best f:  -7.999999999999813\n",
      "Best err:  3.2284970057207735e-07\n",
      "Best f:  -7.999999999999817\n",
      "Best err:  2.968392588752444e-07\n",
      "Best f:  -7.9999999999998845\n",
      "Best err:  2.8080436940067665e-07\n",
      "Best f:  -7.9999999999999325\n",
      "Best err:  2.0125919727291525e-07\n",
      "Best f:  -7.9999999999999485\n",
      "Best err:  1.661627632241959e-07\n",
      "Best f:  -7.9999999999999005\n",
      "Best err:  2.3028609189002293e-07\n",
      "Best f:  -7.999999999999702\n",
      "Best err:  3.575487541376214e-07\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../../src/controlled_unitary_optimizer\")\n",
    "sys.path.append(\"../../src/brickwall_ansatz\")\n",
    "from optimize_3q import optimize_3q \n",
    "from utils_3q import make_controlled, random_unitary\n",
    "\n",
    "Xlists_opt = {}\n",
    "#perms_qc = [[0, 1], [0, 2], [1, 2], [0, 2], [0, 1], [1, 2], [0, 2], [0, 1], [1, 2], [1, 2], [0, 1], [0, 2]]\n",
    "perms_qc = [[0, 1], [0, 2], [1, 2], [0, 2], [0, 1], [1, 2], [0, 2], [0, 1], [1, 2]]\n",
    "#perms_qc = [[0, 1], [0, 2], [1, 2], [0, 2], [0, 1]]\n",
    "\n",
    "for i in control_layers:\n",
    "    cU = make_controlled(Vlist[i])\n",
    "    f_best, err_best, Glist_best = (0, 2, None)\n",
    "    for _ in range(5):\n",
    "        Xlist_start = [random_unitary(4) for i in range(len(perms_qc))]\n",
    "        Xlist, f_iter, err_iter = optimize_3q(L, cU, Xlist_start, perms_qc, niter=1000)\n",
    "        if err_iter[-1] < err_best:\n",
    "            f_best, err_best, Xlist_best = (f_iter[-1], err_iter[-1], Xlist)\n",
    "    print(\"Best f: \", f_best)\n",
    "    print(\"Best err: \", err_best)\n",
    "    Xlists_opt[i] = Xlist_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "26124d0a-75b8-46c3-ac05-cfba20d0bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0.125, Gate count:  {'initialize': 1, 'u3': 1266, 'cx': 768, 'rz': 32}  SV error:  0.009170557433636928\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Now here is to compare the performance of the ccU circuit\n",
    "    with the 1st and 2nd order Trotter circuits, in terms of \n",
    "    gate count vs Trotter error. I demonstrate it on L=10 system.\n",
    "\"\"\"\n",
    "import qiskit\n",
    "from qiskit import Aer, execute, transpile\n",
    "from qiskit.circuit.library import CYGate, CZGate, IGate, CXGate\n",
    "from qiskit.converters import circuit_to_dag\n",
    "from qiskit.providers.aer.noise import NoiseModel, errors\n",
    "from qiskit import Aer, execute, transpile\n",
    "from scipy import sparse as sp\n",
    "\n",
    "\n",
    "def controlled_trotter(t, L, J, h, perms_1, perms_2, perms_3, dag=False, nsteps=2, trotter_order=2):\n",
    "    t = t/nsteps\n",
    "    #print(\"nsteps \", nsteps)\n",
    "    \n",
    "    hloc1 = construct_heisenberg_local_term((J[0], 0   ,    0), (0, h[1],    0), ndim=2)\n",
    "    hloc2 = construct_heisenberg_local_term((0   ,    J[1], 0), (0, 0, h[2]   ), ndim=2)\n",
    "    hloc3 = construct_heisenberg_local_term((0   , 0   , J[2]), (h[0], 0,    0), ndim=2)\n",
    "    hlocs = (hloc1, hloc2, hloc3)\n",
    "\n",
    "    # Suzuki splitting\n",
    "    if trotter_order > 1:\n",
    "        sm = oc.SplittingMethod.suzuki(len(hlocs), int(np.log(trotter_order)/np.log(2)))\n",
    "        indices, coeffs = sm.indices, sm.coeffs\n",
    "    else:\n",
    "        indices, coeffs = range(len(hlocs)), [1]*len(hlocs)\n",
    "    perms_ext = [perms_1, perms_2, perms_3]*len(indices)\n",
    "    \n",
    "    cgates = ((CXGate, CZGate), \n",
    "              (CXGate, CYGate), \n",
    "              (CZGate, CYGate))\n",
    "    \n",
    "    K = []\n",
    "    for i, perms in enumerate(perms_ext):\n",
    "        sub = int(i//3)\n",
    "        index = indices[sub]\n",
    "        perm = perms[0]\n",
    "        K_layer = [None for _ in range(L)]\n",
    "        for j in range(len(perm)//2):\n",
    "            K_layer[perm[2*j]] =  cgates[index][0]\n",
    "            K_layer[perm[2*j+1]] =  cgates[index][1]\n",
    "        K.append(K_layer)\n",
    "\n",
    "    Vlist_start = []\n",
    "    for i, c in zip(indices, coeffs):\n",
    "        Vlist_start.append(scipy.linalg.expm(-1j*c*t*hlocs[i]))\n",
    "    Vlist_gates = []\n",
    "    for V in Vlist_start:\n",
    "        qc2 = qiskit.QuantumCircuit(2)\n",
    "        qc2.unitary(V, [0, 1], label='str')\n",
    "        Vlist_gates.append(qc2)\n",
    "    \n",
    "    qc = qiskit.QuantumCircuit(L+1)\n",
    "    for n in range(nsteps):\n",
    "        for layer, qc_gate in enumerate(Vlist_gates):\n",
    "            for _, perms in enumerate([perms_1, perms_2, perms_3]):\n",
    "                qc.x(L)\n",
    "                for j in range(L):\n",
    "                    if K[3*layer+_][j]:\n",
    "                        qc.append(K[3*layer+_][j](), [L, L-1-j])\n",
    "                qc.x(L)\n",
    "                \n",
    "                for perm in perms:\n",
    "                    for j in range(len(perm)//2):\n",
    "                        qc.append(qc_gate.to_gate(), [L-(perm[2*j]+1), L-(perm[2*j+1]+1)])\n",
    "                        \n",
    "                qc.x(L)\n",
    "                for j in range(L):\n",
    "                    if K[3*layer+_][j]:\n",
    "                        qc.append(K[3*layer+_][j](), [L, L-1-j])\n",
    "                qc.x(L)\n",
    "\n",
    "    return qc\n",
    "\n",
    "trotter1_cxs_01 = []\n",
    "trotter1_errs_01 = []\n",
    "for t_ in [t]:\n",
    "    state = random_statevector(2**L).data\n",
    "    qc_ext1 = qiskit.QuantumCircuit(L+1)\n",
    "    qc_ext1.initialize(state, [i for i in range(L)])\n",
    "    qc_ext1.append(controlled_trotter(t_, L, J, h, perms_1, perms_2, perms_3).to_gate(), [i for i in range(L+1)])\n",
    "    backend = Aer.get_backend(\"statevector_simulator\")\n",
    "    sv1_T = execute(transpile(qc_ext1), backend).result().get_statevector().data\n",
    "    \n",
    "    qc_ext2 = qiskit.QuantumCircuit(L+1)\n",
    "    qc_ext2.initialize(state, [i for i in range(L)])\n",
    "    qc_ext2.x(L)\n",
    "    qc_ext2.append(controlled_trotter(t_, L, J, h, perms_1, perms_2, perms_3).to_gate(), [i for i in range(L+1)])\n",
    "    backend = Aer.get_backend(\"statevector_simulator\")\n",
    "    sv2_T = execute(transpile(qc_ext2), backend).result().get_statevector().data\n",
    "\n",
    "    ket_0 = np.array([1, 0])\n",
    "    ket_1 = np.array([0, 1])\n",
    "    exact_v1 = np.kron(ket_0, expm_multiply(1j * t_ * hamil, state))\n",
    "    exact_v2 = np.kron(ket_1, expm_multiply(-1j * t_ * hamil, state))\n",
    "\n",
    "\n",
    "    err1 = 1-state_fidelity(sv1_T, exact_v1)\n",
    "    err2 = 1-state_fidelity(sv2_T, exact_v2)    \n",
    "\n",
    "    noise_model = NoiseModel()\n",
    "    dag = circuit_to_dag(transpile(qc_ext1, optimization_level=2, basis_gates=noise_model.basis_gates+['initialize', 'cx', 'u3']))\n",
    "    count_ops = dag.count_ops()\n",
    "\n",
    "    print(f\"t={t}, Gate count: \", count_ops, \" SV error: \", (err1+err2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "bae1f7bc-db82-4d75-8c92-b4fcf011493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trotter: 768  ->  6912  (N=108)\n",
    "# TICC:    288  ->  2592  (N=108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d105f1-4405-4e20-bde1-da4d61de2a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff68a1e-4c7e-4de4-a1c7-562012e7a337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b3bd2-4309-46a6-982f-e87b6d2aa038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ============================\n",
    "#  Pauli matrices\n",
    "# ============================\n",
    "paulis = [\n",
    "    np.array([[1, 0], [0, 1]], dtype=complex),      # I\n",
    "    np.array([[0, 1], [1, 0]], dtype=complex),      # X\n",
    "    np.array([[0, -1j], [1j, 0]], dtype=complex),   # Y\n",
    "    np.array([[1, 0], [0, -1]], dtype=complex)      # Z\n",
    "]\n",
    "\n",
    "\n",
    "# ============================\n",
    "#  Operator Schmidt Decomposition\n",
    "# ============================\n",
    "def operator_schmidt_decomposition(U):\n",
    "    \"\"\"\n",
    "    Computes the operator Schmidt decomposition of a 4x4 matrix U\n",
    "    expressed in the Pauli ⊗ Pauli basis.\n",
    "\n",
    "    Returns:\n",
    "        S      = Schmidt coefficients (sorted)\n",
    "        A_ops  = local operators A_k (2x2)\n",
    "        B_ops  = local operators B_k (2x2)\n",
    "    \"\"\"\n",
    "\n",
    "    # Build coefficient matrix C_{μν} in Pauli basis\n",
    "    C = np.zeros((4, 4), dtype=complex)\n",
    "    for mu in range(4):\n",
    "        for nu in range(4):\n",
    "            basis = np.kron(paulis[mu], paulis[nu])\n",
    "            # Factor 1/4 because each Pauli has Tr = 2\n",
    "            C[mu, nu] = 0.25 * np.trace(basis.conj().T @ U)\n",
    "\n",
    "    # SVD of coefficient matrix\n",
    "    W, S, Vh = np.linalg.svd(C)\n",
    "    V = Vh.conj().T  # right singular vectors as columns\n",
    "\n",
    "    A_ops = []\n",
    "    B_ops = []\n",
    "\n",
    "    for k in range(4):\n",
    "        # Left singular vector → local operator A_k\n",
    "        A = sum(W[mu, k] * paulis[mu] for mu in range(4))\n",
    "\n",
    "        # IMPORTANT: right singular vector appears with a conjugate\n",
    "        B = sum(np.conj(V[nu, k]) * paulis[nu] for nu in range(4))\n",
    "\n",
    "        A_ops.append(A)\n",
    "        B_ops.append(B)\n",
    "\n",
    "    return S, A_ops, B_ops\n",
    "\n",
    "\n",
    "# ============================\n",
    "#  Project to nearest unitary\n",
    "# ============================\n",
    "def project_to_unitary(A):\n",
    "    \"\"\"\n",
    "    Returns the closest unitary matrix to A\n",
    "    in Frobenius norm using SVD-based polar decomposition.\n",
    "    \"\"\"\n",
    "    W, s, Vh = np.linalg.svd(A)\n",
    "    return W @ Vh\n",
    "\n",
    "\n",
    "# ============================\n",
    "#  Compute best product unitary U1 ⊗ U2 approximating U\n",
    "# ============================\n",
    "def best_local_unitaries(U):\n",
    "    S, A_ops, B_ops = operator_schmidt_decomposition(U)\n",
    "\n",
    "    # Leading Schmidt term (rank-1 factor)\n",
    "    A0 = A_ops[0]\n",
    "    B0 = B_ops[0]\n",
    "\n",
    "    # Project local operators to unitaries\n",
    "    U1 = project_to_unitary(A0)\n",
    "    U2 = project_to_unitary(B0)\n",
    "    U_prod = np.kron(U1, U2)\n",
    "\n",
    "    # Fix global phase to maximize fidelity\n",
    "    overlap = np.trace(U.conj().T @ U_prod)\n",
    "    if np.abs(overlap) > 1e-12:\n",
    "        phase = overlap / np.abs(overlap)\n",
    "        U_prod *= phase\n",
    "\n",
    "    return U1, U2, U_prod, U1, U2\n",
    "\n",
    "\n",
    "# ============================\n",
    "#  TEST: Should recover product exactly\n",
    "# ============================\n",
    "if __name__ == \"__main__\":\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "    U = Vlist[4]\n",
    "    U1_est, U2_est, U_prod, U1, U2 = best_local_unitaries(U)\n",
    "\n",
    "    # Fidelity = |Tr(U† U_prod)| / 4\n",
    "    fidelity = np.abs(np.trace(U.conj().T @ U_prod)) / 4.0\n",
    "\n",
    "    print(\"\\nRecovered single-qubit unitaries:\")\n",
    "    print(\"U1_est:\\n\", U1_est)\n",
    "    print(\"U2_est:\\n\", U2_est)\n",
    "\n",
    "    print(\"\\nRecovered product unitary U1_est ⊗ U2_est:\")\n",
    "    print(U_prod)\n",
    "\n",
    "    print(\"\\nFidelity between U and recovered product:\", fidelity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (qc)",
   "language": "python",
   "name": "qc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
