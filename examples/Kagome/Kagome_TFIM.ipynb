{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "07f6013b-e239-406e-8e34-8f81eb70fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.linalg import expm\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def bonds_from_perms(perms):\n",
    "    \"\"\"\n",
    "    Each row p in perms encodes pairs:\n",
    "    (p[0], p[1]), (p[2], p[3]), ...\n",
    "    \"\"\"\n",
    "    bonds = []\n",
    "    for p in perms:\n",
    "        assert len(p) % 2 == 0\n",
    "        for k in range(0, len(p), 2):\n",
    "            bonds.append((p[k], p[k+1]))\n",
    "    return bonds\n",
    "\n",
    "sx = sp.csr_matrix([[0, 1],\n",
    "                    [1, 0]], dtype=complex)\n",
    "\n",
    "sy = sp.csr_matrix([[0, -1j],\n",
    "                    [1j,  0]], dtype=complex)\n",
    "\n",
    "sz = sp.csr_matrix([[1,  0],\n",
    "                    [0, -1]], dtype=complex)\n",
    "\n",
    "id2 = sp.identity(2, dtype=complex, format='csr')\n",
    "\n",
    "\n",
    "def two_site_pauli_term(L, i, j, pauli1, pauli2):\n",
    "    \"\"\"\n",
    "    Build the operator:\n",
    "        I ⊗ ... ⊗ pauli1(at i) ⊗ ... ⊗ pauli2(at j) ⊗ ... I\n",
    "    \"\"\"\n",
    "    if i == j:\n",
    "        raise ValueError(\"i and j must be different\")\n",
    "\n",
    "    if i > j:\n",
    "        i, j = j, i\n",
    "        pauli1, pauli2 = pauli2, pauli1\n",
    "\n",
    "    ops = []\n",
    "    for site in range(L):\n",
    "        if site == i:\n",
    "            ops.append(pauli1)\n",
    "        elif site == j:\n",
    "            ops.append(pauli2)\n",
    "        else:\n",
    "            ops.append(id2)\n",
    "\n",
    "    op = ops[0]\n",
    "    for k in range(1, L):\n",
    "        op = sp.kron(op, ops[k], format='csr')\n",
    "    return op\n",
    "\n",
    "\n",
    "def build_H(L, bonds, J, h, n_neighbours):\n",
    "    dim = 2**L\n",
    "    H = sp.csr_matrix((dim, dim), dtype=complex)\n",
    "    for (i, j) in bonds:\n",
    "        if J[0] != 0:\n",
    "            H += J[0] * two_site_pauli_term(L, i, j, sx, sx)\n",
    "        if J[1] != 0:\n",
    "            H += J[1] * two_site_pauli_term(L, i, j, sy, sy)\n",
    "        if J[2] != 0:\n",
    "            H += J[2] * two_site_pauli_term(L, i, j, sz, sz)\n",
    "\n",
    "        if h[0] != 0:\n",
    "            H += h[0]  * (two_site_pauli_term(L, i, j, sx, id2) + two_site_pauli_term(L, i, j, id2, sx))/n_neighbours\n",
    "        if h[1] != 0:\n",
    "            H += h[1]  * (two_site_pauli_term(L, i, j, sy, id2) + two_site_pauli_term(L, i, j, id2, sy))/n_neighbours\n",
    "        if h[2] != 0:\n",
    "            H += h[2]  * (two_site_pauli_term(L, i, j, sz, id2) + two_site_pauli_term(L, i, j, id2, sz))/n_neighbours\n",
    "    return H\n",
    "\n",
    "perms_1 = [[0, 4, 6, 10, 2, 5, 8, 11], [4, 6, 10, 0, 5, 8, 11, 2]]\n",
    "perms_2 = [[0, 1, 2, 3, 6, 7, 8, 9], [1, 2, 3, 0, 7, 8, 9, 6]]\n",
    "perms_3 = [[1, 4, 9, 11, 3, 5, 7, 10], [4, 1, 11, 9, 5, 7, 10, 3]]\n",
    "bonds_1 = bonds_from_perms(perms_1)\n",
    "bonds_2 = bonds_from_perms(perms_2)\n",
    "bonds_3 = bonds_from_perms(perms_3)\n",
    "all_bonds = bonds_1 + bonds_2 + bonds_3\n",
    "L = 12\n",
    "J = (0, 0, 1)\n",
    "h = (3, 0, 0)\n",
    "hamil = build_H(L, all_bonds, J, h, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "cc55e864-0eb1-4b41-aa0e-e69061eb9d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trotter error of the starting point:  0.03290317319493108\n",
      "Trotter error of the starting point:  0.03340737673091687\n",
      "Trotter error of the starting point:  0.18285450055700725\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import scipy\n",
    "\n",
    "t = 0.125\n",
    "sys.path.append(\"../../src/brickwall_sparse\")\n",
    "from utils_sparse import construct_ising_local_term, reduce_list, X, I2, get_perms, construct_heisenberg_local_term\n",
    "from ansatz_sparse import ansatz_sparse\n",
    "import rqcopt as oc\n",
    "from scipy.sparse.linalg import expm_multiply\n",
    "from qiskit.quantum_info import random_statevector\n",
    "from scipy.linalg import expm\n",
    "from qiskit.quantum_info import state_fidelity\n",
    "\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "Y = np.array([[0, -1j], [1j, 0]])\n",
    "YZ = np.kron(Y, Z)\n",
    "I2 = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "state = np.array(random_statevector(2**L).data)\n",
    "hloc = construct_heisenberg_local_term((0, 0,    J[2]), (h[0], 0,    0), ndim=2)\n",
    "\n",
    "V = scipy.linalg.expm(-1j*t*hloc)\n",
    "YZ = np.kron(Y, Z)\n",
    "Vlist_start =  [YZ, V, YZ, YZ, V, YZ, YZ, V, YZ]\n",
    "Vlist_reduced = [V, V, V]\n",
    "perms_extended = [[perms_1[0]]] + [perms_1] + [[perms_1[0]], [perms_2[0]]] +\\\n",
    "                    [perms_2] + [[perms_2[0]], [perms_3[0]]] + [perms_3] + [[perms_3[0]]] \n",
    "perms_ext_reduced = [perms_1]  + [perms_2] + [perms_3]\n",
    "control_layers = [0, 2, 3, 5, 6, 8]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Trotter error of the starting point: \", 1-state_fidelity(ansatz_sparse(Vlist_start, L, perms_extended, state), expm_multiply(\n",
    "    1j * t * hamil, state)))\n",
    "print(\"Trotter error of the starting point: \", 1-state_fidelity(ansatz_sparse(Vlist_reduced, L, perms_ext_reduced, state), expm_multiply(\n",
    "    -1j * t * hamil, state)))\n",
    "print(\"Trotter error of the starting point: \", (np.linalg.norm(ansatz_sparse(Vlist_start, L, perms_extended, state) - expm_multiply(\n",
    "    1j * t * hamil, state), ord=2) + np.linalg.norm(ansatz_sparse(Vlist_reduced, L, perms_ext_reduced, state) - expm_multiply(\n",
    "    -1j * t * hamil, state), ord=2))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "d534d084-0eda-4c23-95d8-a06a0a2fa2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vlist_reduced = [Vlist[1], Vlist[4], Vlist[7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "2a637ee4-e9cf-4183-bc05-02da53d15770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current error:  0.05656376490989869\n",
      "Current error:  0.0547791886874832\n",
      "Current error:  0.05404069128671259\n",
      "Current error:  0.053153338322415936\n",
      "Current error:  0.0517996443601167\n",
      "Current error:  0.051074935646549746\n",
      "Current error:  0.05102848673192702\n",
      "Current error:  0.051008347374989056\n",
      "Current error:  0.050997620938936415\n"
     ]
    }
   ],
   "source": [
    "from optimize_sparse import optimize\n",
    "import h5py\n",
    "\n",
    "niter = 8\n",
    "Vlist, f_iter, err_iter = optimize(L, hamil, t, Vlist, perms_extended, perms_reduced=perms_ext_reduced,\n",
    "                                   control_layers=control_layers, rS=1, niter=niter)\n",
    "\n",
    "with h5py.File(f\"./results/kagome_TFIM_L{L}_t{t}_layers{len(Vlist)}.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\"Vlist\", data=Vlist)\n",
    "    f.create_dataset(\"f_iter\", data=f_iter)\n",
    "    f.create_dataset(\"err_iter\", data=err_iter)\n",
    "    f.attrs[\"L\"] = L\n",
    "    f.attrs[\"t\"] = float(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "1c5150d9-938a-4a88-b947-4a2c52b7dba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030505872711221738"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.abs(np.trace(Vlist[3].conj().T@YZ))/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "135f2a39-3708-45dd-be57-115c900645ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008395094948197512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse as sp\n",
    "from utils_sparse import applyG_state\n",
    "\n",
    "\"\"\"\n",
    "    TODO: Somehow this mapping qiskit -> np isnt working\n",
    "    Maybe do it with applyG and count gates manually\n",
    "\"\"\"\n",
    "\n",
    "sv = random_statevector(2**L).data\n",
    "state1 = np.kron(ket_0, sv)\n",
    "state2 = np.kron(ket_1, sv)\n",
    "\n",
    "\n",
    "def apply(state):\n",
    "    count = 0\n",
    "    for i, V in enumerate(Vlist):\n",
    "        layer = i\n",
    "        if i in control_layers:\n",
    "            Glist = Xlists_opt[i]\n",
    "            for perm in perms_extended[i]:\n",
    "                for j in range(len(perm)//2):\n",
    "                    for _, G in enumerate(Glist):\n",
    "                        \n",
    "                        mapping = {0: 0, 1: perm[2*j]+1, 2: perm[2*j+1]+1}\n",
    "                        state = applyG_state(G, state, L+1, mapping[perms_qc[_][0]], mapping[perms_qc[_][1]])\n",
    "                        count += 1\n",
    "                \n",
    "        else:\n",
    "            for perm in perms_extended[layer]:\n",
    "                for j in range(len(perm)//2):\n",
    "                    state = applyG_state(V, state, L+1, perm[2*j]+1, perm[2*j+1]+1)\n",
    "                    count += 2\n",
    "    return state, count\n",
    "\n",
    "sv1, count = apply(state1)\n",
    "sv2, count1 = apply(state2)\n",
    "\n",
    "exact_v1 = np.kron(ket_0, expm_multiply(-1j * t * hamil, sv))\n",
    "exact_v2 = np.kron(ket_1, expm_multiply(1j * t * hamil, sv))\n",
    "print((1-state_fidelity(sv1, exact_v1) + 1-state_fidelity(sv2, exact_v2))/2)\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "b3229743-12d1-400a-a8b2-54b2bab206a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trotter error of the starting point:  0.03328163928851957\n",
      "Trotter error of the optimized point:  0.0008792940316135756\n",
      "Trotter error of the optimized point:  0.0055832608608638035\n"
     ]
    }
   ],
   "source": [
    "state = random_statevector(2**L).data\n",
    "perms_extended = [[perms_1[0]]] + [perms_1] + [[perms_1[0]], [perms_2[0]]] +\\\n",
    "                    [perms_2] + [[perms_2[0]], [perms_3[0]]] + [perms_3] + [[perms_3[0]]] \n",
    "perms_ext_reduced = [perms_1]  + [perms_2] + [perms_3]\n",
    "control_layers = [0, 2, 3, 5, 6, 8]\n",
    "\n",
    "print(\"Trotter error of the starting point: \", 1-state_fidelity(ansatz_sparse(Vlist_start, L, perms_extended, state), expm_multiply(\n",
    "    1j * t * hamil, state)))\n",
    "print(\"Trotter error of the optimized point: \", 1-state_fidelity(ansatz_sparse(Vlist, L, perms_extended, state), expm_multiply(\n",
    "    1j * t * hamil, state)))\n",
    "print(\"Trotter error of the optimized point: \", 1-state_fidelity(ansatz_sparse(Vlist_reduced, L, perms_ext_reduced, state), expm_multiply(\n",
    "    -1j * t * hamil, state)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "d62b37e1-0722-4806-886a-df1c73f7cb87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f:  -7.997335067749082\n",
      "Best err:  0.043072540679392035\n",
      "Best f:  -7.9960145490121235\n",
      "Best err:  0.047422968707125784\n",
      "Best f:  -7.991867420619622\n",
      "Best err:  0.07075146468588212\n",
      "Best f:  -7.989858330512304\n",
      "Best err:  0.07243093074871985\n",
      "Best f:  -7.994931805551152\n",
      "Best err:  0.054706417514804304\n",
      "Best f:  -7.993406911607346\n",
      "Best err:  0.06075363325790433\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../../src/controlled_unitary_optimizer\")\n",
    "sys.path.append(\"../../src/brickwall_ansatz\")\n",
    "from optimize_3q import optimize_3q \n",
    "from utils_3q import make_controlled, random_unitary\n",
    "\n",
    "Xlists_opt = {}\n",
    "#perms_qc = [[0, 1], [0, 2], [1, 2], [0, 2], [0, 1], [1, 2], [0, 2], [0, 1], [1, 2], [1, 2], [0, 1], [0, 2]]\n",
    "perms_qc = [[0, 1], [0, 2]]\n",
    "\n",
    "for i in control_layers:\n",
    "    cU = make_controlled(Vlist[i])\n",
    "    f_best, err_best, Glist_best = (0, 2, None)\n",
    "    for _ in range(3):\n",
    "        Xlist_start = [random_unitary(4) for i in range(len(perms_qc))]\n",
    "        Xlist, f_iter, err_iter = optimize_3q(L, cU, Xlist_start, perms_qc, niter=1000)\n",
    "        if err_iter[-1] < err_best:\n",
    "            f_best, err_best, Xlist_best = (f_iter[-1], err_iter[-1], Xlist)\n",
    "    print(\"Best f: \", f_best)\n",
    "    print(\"Best err: \", err_best)\n",
    "    Xlists_opt[i] = Xlist_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "a22dd460-9659-4fdd-9c76-7da9a51d469a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0753136656590025\n"
     ]
    }
   ],
   "source": [
    "import qiskit\n",
    "from qiskit import Aer, execute, transpile\n",
    "from qiskit.circuit.library import CYGate, CZGate, IGate, CXGate\n",
    "from qiskit.converters import circuit_to_dag\n",
    "from qiskit.providers.aer.noise import NoiseModel, errors\n",
    "from qiskit import Aer, execute, transpile\n",
    "from scipy import sparse as sp\n",
    "\n",
    "\"\"\"qc = qiskit.QuantumCircuit(L+1)\n",
    "qc.x(L)\n",
    "for i, V in enumerate(Vlist):\n",
    "    layer = i\n",
    "    if i in control_layers:\n",
    "        G = make_controlled(Vlist[i])\n",
    "        #Glist = Xlists_opt[i]\n",
    "        qc_3 = qiskit.QuantumCircuit(3)\n",
    "        #for j, G in enumerate(Glist):\n",
    "        #    qc_3.unitary( G, (3-1-perms_qc[j][1], 3-1-perms_qc[j][0]))\n",
    "        qc_3.unitary( G, [0, 1, 2])\n",
    "        \n",
    "        for perm in perms_extended[layer]:\n",
    "            for j in range(len(perm)//2):\n",
    "                qc.append(qc_3.to_gate(), [L-perm[2*j]-1, L-perm[2*j+1]-1, L])\n",
    "        \n",
    "    else:\n",
    "        for perm in perms_extended[layer]:\n",
    "            for j in range(len(perm)//2):\n",
    "                qc.unitary(V, [L-perm[2*j]-1, L-perm[2*j+1]-1])\n",
    "qc.x(L)\"\"\"\n",
    "\n",
    "\n",
    "ccU_cxs= []\n",
    "ccU_errs = []\n",
    "for t_ in [0.125]:\n",
    "    state = random_statevector(2**L).data\n",
    "    qc_ext1 = qiskit.QuantumCircuit(L+1)\n",
    "    qc_ext1.initialize(state, [i for i in range(L)])\n",
    "    for i in range(int(t_/t)):\n",
    "        qc_ext1.append(qc.to_gate(), [i for i in range(L+1)])\n",
    "    backend = Aer.get_backend(\"statevector_simulator\")\n",
    "    sv1 = execute(transpile(qc_ext1), backend).result().get_statevector().data\n",
    "    #sv1 = np.kron(ket_0, ansatz_sparse(Vlist, L, perms_extended, state))\n",
    "    \n",
    "    qc_ext2 = qiskit.QuantumCircuit(L+1)\n",
    "    qc_ext2.initialize(state, [i for i in range(L)])\n",
    "    qc_ext2.x(L)\n",
    "    for i in range(int(t_/t)):\n",
    "        qc_ext2.append(qc.to_gate(), [i for i in range(L+1)])\n",
    "    backend = Aer.get_backend(\"statevector_simulator\")\n",
    "    sv2 = execute(transpile(qc_ext2), backend).result().get_statevector().data\n",
    "    #sv2 = np.kron(ket_1, ansatz_sparse(Vlist_reduced, L, perms_ext_reduced, state))\n",
    "\n",
    "    ket_0 = np.array([1, 0])\n",
    "    ket_1 = np.array([0, 1])\n",
    "    exact_v1 = np.kron(ket_0, expm_multiply(1j * t_ * hamil, state))\n",
    "    exact_v2 = np.kron(ket_1, expm_multiply(-1j * t_ * hamil, state))\n",
    "    err = (np.linalg.norm(sv1-exact_v1, ord=2) + np.linalg.norm(sv2-exact_v2, ord=2))/2\n",
    "    print((1-state_fidelity(sv1, exact_v1) + 1-state_fidelity(sv2, exact_v2))/2)\n",
    "    \n",
    "    noise_model = NoiseModel()\n",
    "    dag = circuit_to_dag(transpile(qc_ext1, basis_gates=noise_model.basis_gates+['unitary', 'initialize', 'cx']))\n",
    "    count_ops = dag.count_ops()\n",
    "    \n",
    "    ccU_errs.append(err)\n",
    "    ccU_cxs.append(count_ops['unitary'])\n",
    "    #print(f\"t={t_}, Gate Count: \", count_ops['unitary'], \" Trotter error: \", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "26124d0a-75b8-46c3-ac05-cfba20d0bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsteps  1\n",
      "nsteps  1\n",
      "t=0.125, Gate count:  {'initialize': 1, 'u3': 222, 'rz': 12, 'cx': 128}  SV error:  0.007211448953165389\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Now here is to compare the performance of the ccU circuit\n",
    "    with the 1st and 2nd order Trotter circuits, in terms of \n",
    "    gate count vs Trotter error. I demonstrate it on L=10 system.\n",
    "\"\"\"\n",
    "\n",
    "from qiskit import Aer, execute, transpile\n",
    "from qiskit.circuit.library import CYGate, CZGate, IGate, CXGate\n",
    "from qiskit.converters import circuit_to_dag\n",
    "from qiskit.providers.aer.noise import NoiseModel, errors\n",
    "from qiskit import Aer, execute, transpile\n",
    "from scipy import sparse as sp\n",
    "\n",
    "\n",
    "def controlled_trotter(t, L, Lx, Ly, J, h, perms_1, perms_2, perms_3, dag=False, nsteps=1, trotter_order=2):\n",
    "    t = t/nsteps\n",
    "    print(\"nsteps \", nsteps)\n",
    "\n",
    "    hloc1 = construct_heisenberg_local_term((0, 0   ,    J[2]), (0, 0,       0), ndim=2)\n",
    "    hloc2 = construct_heisenberg_local_term((0   ,    0, 0), (h[0], 0, 0      ), ndim=2)\n",
    "    #hloc3 = construct_heisenberg_local_term((0   , 0   , J[2]), (h[0], 0,       0), ndim=2)\n",
    "    hlocs = (hloc1,hloc2, )\n",
    "\n",
    "    # Suzuki splitting\n",
    "    if trotter_order > 1:\n",
    "        sm = oc.SplittingMethod.suzuki(len(hlocs), int(np.log(trotter_order)/np.log(2)))\n",
    "        indices, coeffs = sm.indices, sm.coeffs\n",
    "    else:\n",
    "        indices, coeffs = range(len(hlocs)), [1]*len(hlocs)\n",
    "    perms_ext = [perms_1, perms_2, perms_3]*len(indices)\n",
    "    \n",
    "    cgates = ((CYGate, None),\n",
    "              (CYGate, CYGate),\n",
    "             )\n",
    "    \n",
    "    K = []\n",
    "    for i, perms in enumerate(perms_ext):\n",
    "        sub = int(i//3)\n",
    "        index = indices[sub]\n",
    "        perm = perms[0]\n",
    "        K_layer = [None for _ in range(L)]\n",
    "        for j in range(len(perm)//2):\n",
    "            K_layer[perm[2*j]] =  cgates[index][0]\n",
    "            K_layer[perm[2*j+1]] =  cgates[index][1]\n",
    "        K.append(K_layer)\n",
    "\n",
    "    Vlist_start = []\n",
    "    for i, c in zip(indices, coeffs):\n",
    "        Vlist_start.append(scipy.linalg.expm(-1j*c*t*hlocs[i]))\n",
    "    Vlist_gates = []\n",
    "    for V in Vlist_start:\n",
    "        qc2 = qiskit.QuantumCircuit(2)\n",
    "        qc2.unitary(V, [0, 1], label='str')\n",
    "        Vlist_gates.append(qc2)\n",
    "    \n",
    "    qc = qiskit.QuantumCircuit(L+1)\n",
    "    for n in range(nsteps):\n",
    "        for layer, qc_gate in enumerate(Vlist_gates):\n",
    "            for _, perms in enumerate([perms_1, perms_2, perms_3]):\n",
    "                qc.x(L)\n",
    "                for j in range(L):\n",
    "                    if K[3*layer+_][j]:\n",
    "                        qc.append(K[3*layer+_][j](), [L, L-1-j])\n",
    "                qc.x(L)\n",
    "                \n",
    "                for perm in perms:\n",
    "                    for j in range(len(perm)//2):\n",
    "                        qc.append(qc_gate.to_gate(), [L-(perm[2*j]+1), L-(perm[2*j+1]+1)])\n",
    "                        \n",
    "                qc.x(L)\n",
    "                for j in range(L):\n",
    "                    if K[3*layer+_][j]:\n",
    "                        qc.append(K[3*layer+_][j](), [L, L-1-j])\n",
    "                qc.x(L)\n",
    "\n",
    "    return qc\n",
    "\n",
    "trotter1_cxs_01 = []\n",
    "trotter1_errs_01 = []\n",
    "for t_ in [t]:\n",
    "    state = random_statevector(2**L).data\n",
    "    qc_ext1 = qiskit.QuantumCircuit(L+1)\n",
    "    qc_ext1.initialize(state, [i for i in range(L)])\n",
    "    qc_ext1.append(controlled_trotter(t_, L, Lx, Ly, J, h, perms_1, perms_2, perms_3).to_gate(), [i for i in range(L+1)])\n",
    "    backend = Aer.get_backend(\"statevector_simulator\")\n",
    "    sv1_T = execute(transpile(qc_ext1), backend).result().get_statevector().data\n",
    "    \n",
    "    qc_ext2 = qiskit.QuantumCircuit(L+1)\n",
    "    qc_ext2.initialize(state, [i for i in range(L)])\n",
    "    qc_ext2.x(L)\n",
    "    qc_ext2.append(controlled_trotter(t_, L, Lx, Ly, J, h, perms_1, perms_2, perms_3).to_gate(), [i for i in range(L+1)])\n",
    "    backend = Aer.get_backend(\"statevector_simulator\")\n",
    "    sv2_T = execute(transpile(qc_ext2), backend).result().get_statevector().data\n",
    "\n",
    "    ket_0 = np.array([1, 0])\n",
    "    ket_1 = np.array([0, 1])\n",
    "    exact_v1 = np.kron(ket_0, expm_multiply(1j * t_ * hamil, state))\n",
    "    exact_v2 = np.kron(ket_1, expm_multiply(-1j * t_ * hamil, state))\n",
    "    \n",
    "    #err = (np.linalg.norm(sv1_T-exact_v1, ord=2) + np.linalg.norm(sv2_T-exact_v2, ord=2))/2\n",
    "    err1 = 1-state_fidelity(sv1_T, exact_v1)\n",
    "    err2 = 1-state_fidelity(sv2_T, exact_v2)\n",
    "    \n",
    "    #err1 = np.linalg.norm(sv1_T - exact_v1, ord=2) \n",
    "    #err2 = np.linalg.norm(sv2_T - exact_v2, ord=2)\n",
    "\n",
    "    noise_model = NoiseModel()\n",
    "    dag = circuit_to_dag(transpile(qc_ext1, optimization_level=2, basis_gates=noise_model.basis_gates+['initialize', 'cx', 'u3']))\n",
    "    count_ops = dag.count_ops()\n",
    "\n",
    "    trotter1_cxs_01.append(count_ops['cx'])\n",
    "    trotter1_errs_01.append(err)\n",
    "\n",
    "    print(f\"t={t}, Gate count: \", count_ops, \" SV error: \", (err1+err2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae1f7bc-db82-4d75-8c92-b4fcf011493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trotter: 128 -> 3312 (N=108)\n",
    "# TICC:    96 ->  864  (N=108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d105f1-4405-4e20-bde1-da4d61de2a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff68a1e-4c7e-4de4-a1c7-562012e7a337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b3bd2-4309-46a6-982f-e87b6d2aa038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (qc)",
   "language": "python",
   "name": "qc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
