{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "975a4b35-6817-408f-8526-a9318a74bacb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0/8, layer 0/3 applied\n",
      "Time step 0/8, layer 1/3 applied\n",
      "Time step 0/8, layer 2/3 applied\n",
      "Time step 1/8, layer 0/3 applied\n",
      "Time step 1/8, layer 1/3 applied\n",
      "Time step 1/8, layer 2/3 applied\n",
      "Time step 2/8, layer 0/3 applied\n",
      "Time step 2/8, layer 1/3 applied\n",
      "Time step 2/8, layer 2/3 applied\n",
      "Time step 3/8, layer 0/3 applied\n",
      "Time step 3/8, layer 1/3 applied\n",
      "Time step 3/8, layer 2/3 applied\n",
      "Time step 4/8, layer 0/3 applied\n",
      "Time step 4/8, layer 1/3 applied\n",
      "Time step 4/8, layer 2/3 applied\n",
      "Time step 5/8, layer 0/3 applied\n",
      "Time step 5/8, layer 1/3 applied\n",
      "Time step 5/8, layer 2/3 applied\n",
      "Time step 6/8, layer 0/3 applied\n",
      "Time step 6/8, layer 1/3 applied\n",
      "Time step 6/8, layer 2/3 applied\n",
      "Time step 7/8, layer 0/3 applied\n",
      "Time step 7/8, layer 1/3 applied\n",
      "Time step 7/8, layer 2/3 applied\n",
      "Norm. Trotter\n",
      "norm finished Trotter\n",
      "Trotter Fidelity: 0.9356534091018119\n",
      "Step 0 took 0.01 seconds\n",
      "Step 1 took 0.01 seconds\n",
      "Step 1 took 0.02 seconds\n",
      "Step 2 took 0.01 seconds\n",
      "Step 2 took 0.02 seconds\n",
      "Step 3 took 0.01 seconds\n",
      "Step 3 took 0.02 seconds\n",
      "Step 4 took 0.01 seconds\n",
      "Step 5 took 0.01 seconds\n",
      "Step 6 took 0.01 seconds\n",
      "Step 6 took 0.02 seconds\n",
      "Step 7 took 0.01 seconds\n",
      "Step 7 took 0.02 seconds\n",
      "Step 8 took 0.01 seconds\n",
      "Step 8 took 0.02 seconds\n",
      "Step 9 took 0.01 seconds\n",
      "Step 10 took 0.01 seconds\n",
      "Step 11 took 0.01 seconds\n",
      "Step 11 took 0.02 seconds\n",
      "Step 12 took 0.01 seconds\n",
      "Step 12 took 0.02 seconds\n",
      "Step 13 took 0.01 seconds\n",
      "Step 13 took 0.02 seconds\n",
      "Step 14 took 0.01 seconds\n",
      "Normalize ccU\n",
      "Normalization of ccU finished\n",
      "ccU Fidelity after identity: 0.9946310355864794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8746437866859175"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src/brickwall_sparse\")\n",
    "from utils_sparse import applyG_block_state, get_perms\n",
    "\n",
    "import numpy as np\n",
    "import quimb.tensor as qtn\n",
    "import quimb\n",
    "from quimb.tensor.tensor_2d_tebd import TEBD2D, LocalHam2D\n",
    "import scipy\n",
    "import h5py\n",
    "import qib\n",
    "import rqcopt as oc\n",
    "from scipy.sparse.linalg import expm_multiply\n",
    "\n",
    "import time\n",
    "import tracemalloc\n",
    "tracemalloc.start()\n",
    "\n",
    "\n",
    "Vlist = []\n",
    "with h5py.File(f\"./results/tfim2d_ccU_SPARSE_103_Lx4Ly4_t0.25_layers15_rS1_niter15_3hloc.hdf5\", \"r\") as f:\n",
    "    Vlist =  f[\"Vlist\"][:]\n",
    "control_layers = [0, 4, 5, 9, 10, 14]\n",
    "perms_qc = [[0, 1], [0, 2], [1, 2], [0, 2], [0, 1], [1, 2], [0, 2], [0, 1], [1, 2]]\n",
    "Xlists_opt = {}\n",
    "for i in control_layers:\n",
    "    with h5py.File(f\"./results/tfim2d_ccU_SPARSE_103_Lx4Ly4_t0.25_layers15_niter20_rS5_DECOMPOSE_n9_layer{i}.hdf5\", \"r\") as file:\n",
    "        Xlists_opt[i] = file[f\"Xlist_{i}\"][:]\n",
    "\n",
    "Lx, Ly = (4, 4)\n",
    "L = Lx*Ly\n",
    "latt = qib.lattice.IntegerLattice((Lx, Ly), pbc=True)\n",
    "field = qib.field.Field(qib.field.ParticleType.QUBIT, latt)\n",
    "J, h, g = (1, 0, 3)\n",
    "hamil = qib.IsingHamiltonian(field, J, h, g).as_matrix()\n",
    "\n",
    "perms_v, perms_h = get_perms(Lx, Ly)\n",
    "\"\"\"perms_v, perms_h = (\n",
    "    [[0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
    "    [1, 2, 3, 4, 5, 0, 7, 8, 9, 10, 11, 6, 13, 14, 15, 16, 17, 12, 19, 20, 21, 22, 23, 18, 25, 26, 27, 28, 29, 24, 31, 32, 33, 34, 35, 30]],\n",
    "    [[0, 6, 12, 18, 24, 30, 1, 7, 13, 19, 25, 31, 2, 8, 14, 20, 26, 32, 3, 9, 15, 21, 27, 33, 4, 10, 16, 22, 28, 34, 5, 11, 17, 23, 29, 35], \n",
    "    [6, 12, 18, 24, 30, 0, 7, 13, 19, 25, 31, 1, 8, 14, 20, 26, 32, 2, 9, 15, 21, 27, 33, 3, 10, 16, 22, 28, 34, 4, 11, 17, 23, 29, 35, 5]]\n",
    ")\"\"\"\n",
    "perms_extended = [[perms_v[0]]] + [perms_v]*3 + [[perms_v[0]], [perms_h[0]]] +\\\n",
    "                    [perms_h]*3 + [[perms_h[0]], [perms_v[0]]] + [perms_v]*3 + [[perms_v[0]]]\n",
    "perms_ext_reduced = [perms_v]*3  + [perms_h]*3 + [perms_v]*3\n",
    "map_ = {i: (i//Ly, i%Lx) for i in range(L)}\n",
    "\n",
    "peps = qtn.PEPS.rand(Lx, Ly, bond_dim=1, phys_dim=2, cyclic=True)\n",
    "peps /= peps.norm()\n",
    "sv = peps.to_dense()[:, 0]\n",
    "sv = expm_multiply(1j * 0.25 * hamil, sv)\n",
    "peps_trotter = trotter(peps.copy(), -0.25, L, Lx, Ly, J, g, perms_v, perms_h, dt=0.25/8, max_bond_dim=3, lower_max_bond_dim=3, treshold=10)\n",
    "f = quimb.fidelity(peps_trotter.to_dense()[:, 0], sv)\n",
    "print(\"Trotter Fidelity:\", f)  # Should be ≈1\n",
    "\n",
    "\n",
    "peps_ccU = ccU(peps.copy(), Vlist, perms_extended, control_layers, dagger=True, max_bond_dim=3, lower_max_bond_dim=3, treshold=10)\n",
    "f = quimb.fidelity(peps_ccU.to_dense()[:, 0], sv)\n",
    "print(\"ccU Fidelity after identity:\", f)  # Should be ≈1\n",
    "\n",
    "np.linalg.norm(peps_ccU.overlap(peps_trotter))**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a772f58-2869-4501-9726-44d5fd270915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8255531339346395"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_sites = [(2,2), (2,3), (3,2), (3,3)]\n",
    "rho_trotter = peps_trotter.partial_trace(block_sites, optimize='auto-hq', max_bond=3)\n",
    "\n",
    "block_sites = [(2,2), (2,3), (3,2), (3,3)]\n",
    "rho_ccU = peps_ccU.partial_trace(block_sites, optimize='auto-hq', max_bond=3)\n",
    "\n",
    "np.abs(np.trace(rho_ccU.conj().T @ rho_trotter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2925a975-7ea8-4d51-b6fe-8fc364f28446",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('peps_ccU_MOCK.h5', 'w') as f:\n",
    "    for site, t in enumerate(peps_ccU.tensors):\n",
    "        dset_name = f\"site_{site}\"\n",
    "        dset = f.create_dataset(dset_name, data=t.data)\n",
    "        inds_ascii = [ind.encode('ascii', 'ignore') for ind in t.inds]\n",
    "        dset.attrs['inds'] = inds_ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4311235d-2266-42f6-85b7-3c045f91ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = []\n",
    "with h5py.File('peps_ccU_MOCK.h5', 'r') as f:\n",
    "    for key in sorted(f.keys(), key=lambda x: int(x.split('_')[1])):\n",
    "        data = np.array(f[key][:], dtype=np.float64)  # Force NumPy + valid dtype\n",
    "        inds = list(f[key].attrs['inds'])\n",
    "        tensors.append(qtn.Tensor(data=data, inds=inds))\n",
    "\n",
    "arrays = tuple(\n",
    "    tuple(tensors[i * Ly + j] for j in range(Ly))\n",
    "    for i in range(Lx)\n",
    ")\n",
    "\n",
    "peps_loaded = qtn.PEPS(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1595ad69-83db-4a43-9d1b-3e4f76130bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rqcopt as oc\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "I2 = np.eye(2)\n",
    "\n",
    "def trotter(peps, t, L, Lx, Ly, J, g, perms_v, perms_h, dag=False, max_bond_dim=5, \n",
    "            dt=0.1, trotter_order=2, treshold=10, lower_max_bond_dim=4):\n",
    "    nsteps = np.abs(int(np.ceil(t/dt)))\n",
    "    t = t/nsteps\n",
    "    indices = oc.SplittingMethod.suzuki(2, int(np.log(trotter_order)/np.log(2))).indices\n",
    "    coeffs = oc.SplittingMethod.suzuki(2, int(np.log(trotter_order)/np.log(2))).coeffs\n",
    "    \n",
    "    hloc1 = g*(np.kron(X, I2)+np.kron(I2, X))/4\n",
    "    hloc2 = J*np.kron(Z, Z)\n",
    "    hlocs = (hloc1, hloc2)\n",
    "    Vlist_start = []\n",
    "    for i, c in zip(indices, coeffs):\n",
    "        Vlist_start.append(-1j*c*t*hlocs[i])\n",
    "\n",
    "    for n in range(nsteps):\n",
    "        for layer, V in enumerate(Vlist_start):\n",
    "            i = n*len(Vlist_start)+layer\n",
    "            for perm in perms_h:\n",
    "                ordering = {(map_[perm[2*j]], map_[perm[2*j+1]]): V for j in range(L//2)}\n",
    "                start = time.time()\n",
    "                t = TEBD2D(peps, ham=LocalHam2D(Lx, Ly, ordering, cyclic=True),\n",
    "                    tau=-1, D=max_bond_dim if i<treshold else lower_max_bond_dim, chi=1)\n",
    "                t.sweep(tau=-1)\n",
    "                peps = t.state\n",
    "                \n",
    "            for perm in perms_v:\n",
    "                ordering = {(map_[perm[2*j]], map_[perm[2*j+1]]): V for j in range(L//2)}\n",
    "                start = time.time()\n",
    "                t = TEBD2D(peps, ham=LocalHam2D(Lx, Ly, ordering, cyclic=True),\n",
    "                    tau=-1, D=max_bond_dim if i<treshold else lower_max_bond_dim, chi=1)\n",
    "                t.sweep(tau=-1)\n",
    "                peps = t.state\n",
    "            #with open(f\"trotter_PEPS_log{Lx}{Ly}.txt\", \"a\") as file:\n",
    "            #    file.write(f\"Time step {n}/{nsteps}, layer {layer}/{len(Vlist_start)} applied \\n\")\n",
    "            print(f\"Time step {n}/{nsteps}, layer {layer}/{len(Vlist_start)} applied\")\n",
    "    print(f\"Norm. Trotter\")\n",
    "    peps /= peps.norm()\n",
    "    print(f\"norm finished Trotter\")\n",
    "    return peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3546982-58c7-43a5-ba02-4f4b0ee80083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccU(peps, Vlist, perms_extended, control_layers, dagger=False, max_bond_dim=10, lower_max_bond_dim=4, treshold=10):\n",
    "    for i, V in enumerate(Vlist):\n",
    "        if dagger or i not in control_layers:\n",
    "            perms = perms_extended[i]\n",
    "            for perm in perms:\n",
    "                ordering = {(map_[perm[2*j]], map_[perm[2*j+1]]): scipy.linalg.logm(V) for j in range(L//2)}\n",
    "                start = time.time()\n",
    "                t = TEBD2D(peps, ham=LocalHam2D(Lx, Ly, ordering, cyclic=True),\n",
    "                    tau=-1, D=max_bond_dim if i<treshold else lower_max_bond_dim, chi=1)\n",
    "                t.sweep(tau=-1)\n",
    "                peps = t.state\n",
    "                #peps /= peps.norm()\n",
    "                print(f\"Step {i} took {time.time() - start:.2f} seconds\")\n",
    "                #print(\"Peak memory:\", tracemalloc.get_traced_memory())\n",
    "    print(f\"Normalize ccU\")\n",
    "    peps /= peps.norm()\n",
    "    print(f\"Normalization of ccU finished\")\n",
    "    return peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579c5b1-714e-47fb-8b0d-ad42a31d4ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee8731-2099-4289-812d-8847dda92af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10cda94-3589-4500-9332-ffef8d50c402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (qc)",
   "language": "python",
   "name": "qc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
