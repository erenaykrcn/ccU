{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "975a4b35-6817-408f-8526-a9318a74bacb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0/10, layer 0/3 applied\n",
      "Time step 0/10, layer 1/3 applied\n",
      "Time step 0/10, layer 2/3 applied\n",
      "Time step 1/10, layer 0/3 applied\n",
      "Time step 1/10, layer 1/3 applied\n",
      "Time step 1/10, layer 2/3 applied\n",
      "Time step 2/10, layer 0/3 applied\n",
      "Time step 2/10, layer 1/3 applied\n",
      "Time step 2/10, layer 2/3 applied\n",
      "Time step 3/10, layer 0/3 applied\n",
      "Time step 3/10, layer 1/3 applied\n",
      "Time step 3/10, layer 2/3 applied\n",
      "Time step 4/10, layer 0/3 applied\n",
      "Time step 4/10, layer 1/3 applied\n",
      "Time step 4/10, layer 2/3 applied\n",
      "Time step 5/10, layer 0/3 applied\n",
      "Time step 5/10, layer 1/3 applied\n",
      "Time step 5/10, layer 2/3 applied\n",
      "Time step 6/10, layer 0/3 applied\n",
      "Time step 6/10, layer 1/3 applied\n",
      "Time step 6/10, layer 2/3 applied\n",
      "Time step 7/10, layer 0/3 applied\n",
      "Time step 7/10, layer 1/3 applied\n",
      "Time step 7/10, layer 2/3 applied\n",
      "Time step 8/10, layer 0/3 applied\n",
      "Time step 8/10, layer 1/3 applied\n",
      "Time step 8/10, layer 2/3 applied\n",
      "Time step 9/10, layer 0/3 applied\n",
      "Time step 9/10, layer 1/3 applied\n",
      "Time step 9/10, layer 2/3 applied\n",
      "Norm. Trotter\n",
      "norm finished Trotter\n",
      "Step 0 took 0.04 seconds\n",
      "Step 1 took 0.03 seconds\n",
      "Step 1 took 0.04 seconds\n",
      "Step 2 took 0.03 seconds\n",
      "Step 2 took 0.05 seconds\n",
      "Step 3 took 0.03 seconds\n",
      "Step 3 took 0.05 seconds\n",
      "Step 4 took 0.03 seconds\n",
      "Step 5 took 0.03 seconds\n",
      "Step 6 took 0.03 seconds\n",
      "Step 6 took 0.40 seconds\n",
      "Step 7 took 0.03 seconds\n",
      "Step 7 took 0.44 seconds\n",
      "Step 8 took 0.03 seconds\n",
      "Step 8 took 0.39 seconds\n",
      "Step 9 took 0.03 seconds\n",
      "Step 10 took 0.03 seconds\n",
      "Step 11 took 0.03 seconds\n",
      "Step 11 took 0.43 seconds\n",
      "Step 12 took 0.03 seconds\n",
      "Step 12 took 0.41 seconds\n",
      "Step 13 took 0.03 seconds\n",
      "Step 13 took 0.45 seconds\n",
      "Step 14 took 0.03 seconds\n",
      "Normalize ccU\n",
      "Normalization of ccU finished\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src/brickwall_sparse\")\n",
    "from utils_sparse import applyG_block_state, get_perms\n",
    "\n",
    "import numpy as np\n",
    "import quimb.tensor as qtn\n",
    "import quimb\n",
    "from quimb.tensor.tensor_2d_tebd import TEBD2D, LocalHam2D\n",
    "import scipy\n",
    "import h5py\n",
    "import qib\n",
    "import rqcopt as oc\n",
    "from scipy.sparse.linalg import expm_multiply\n",
    "\n",
    "import time\n",
    "import tracemalloc\n",
    "tracemalloc.start()\n",
    "\n",
    "\n",
    "Vlist = []\n",
    "with h5py.File(f\"./results/tfim2d_ccU_SPARSE_103_Lx4Ly4_t0.25_layers15_rS1_niter15_3hloc.hdf5\", \"r\") as f:\n",
    "    Vlist =  f[\"Vlist\"][:]\n",
    "control_layers = [0, 4, 5, 9, 10, 14]\n",
    "perms_qc = [[0, 1], [0, 2], [1, 2], [0, 2], [0, 1], [1, 2], [0, 2], [0, 1], [1, 2]]\n",
    "Xlists_opt = {}\n",
    "for i in control_layers:\n",
    "    with h5py.File(f\"./results/tfim2d_ccU_SPARSE_103_Lx4Ly4_t0.25_layers15_niter20_rS5_DECOMPOSE_n9_layer{i}.hdf5\", \"r\") as file:\n",
    "        Xlists_opt[i] = file[f\"Xlist_{i}\"][:]\n",
    "\n",
    "Lx, Ly = (6, 6)\n",
    "L = Lx*Ly\n",
    "latt = qib.lattice.IntegerLattice((Lx, Ly), pbc=True)\n",
    "field = qib.field.Field(qib.field.ParticleType.QUBIT, latt)\n",
    "J, h, g = (1, 0, 3)\n",
    "#hamil = qib.IsingHamiltonian(field, J, h, g).as_matrix()\n",
    "\n",
    "#perms_v, perms_h = get_perms(Lx, Ly)\n",
    "perms_v, perms_h = (\n",
    "    [[0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
    "    [1, 2, 3, 4, 5, 0, 7, 8, 9, 10, 11, 6, 13, 14, 15, 16, 17, 12, 19, 20, 21, 22, 23, 18, 25, 26, 27, 28, 29, 24, 31, 32, 33, 34, 35, 30]],\n",
    "    [[0, 6, 12, 18, 24, 30, 1, 7, 13, 19, 25, 31, 2, 8, 14, 20, 26, 32, 3, 9, 15, 21, 27, 33, 4, 10, 16, 22, 28, 34, 5, 11, 17, 23, 29, 35], \n",
    "    [6, 12, 18, 24, 30, 0, 7, 13, 19, 25, 31, 1, 8, 14, 20, 26, 32, 2, 9, 15, 21, 27, 33, 3, 10, 16, 22, 28, 34, 4, 11, 17, 23, 29, 35, 5]]\n",
    ")\n",
    "perms_extended = [[perms_v[0]]] + [perms_v]*3 + [[perms_v[0]], [perms_h[0]]] +\\\n",
    "                    [perms_h]*3 + [[perms_h[0]], [perms_v[0]]] + [perms_v]*3 + [[perms_v[0]]]\n",
    "perms_ext_reduced = [perms_v]*3  + [perms_h]*3 + [perms_v]*3\n",
    "map_ = {i: (i//Ly, i%Lx) for i in range(L)}\n",
    "\n",
    "peps = qtn.PEPS.rand(Lx, Ly, bond_dim=1, phys_dim=2, cyclic=True)\n",
    "peps.normalize()\n",
    "#sv = peps.to_dense()[:, 0]\n",
    "#sv = expm_multiply(1j * 0.25 * hamil, sv)\n",
    "peps_trotter = trotter(peps.copy(), -0.25, L, Lx, Ly, J, g, perms_v, perms_h, dt=0.25/10, max_bond_dim=3, lower_max_bond_dim=3, treshold=10)\n",
    "#f = quimb.fidelity(peps_trotter.to_dense()[:, 0], sv)\n",
    "#print(\"Trotter Fidelity:\", f)  # Should be ≈1\n",
    "\n",
    "\n",
    "peps_ccU = ccU(peps.copy(), Vlist, perms_extended, control_layers, dagger=True, max_bond_dim=3, lower_max_bond_dim=3, treshold=10)\n",
    "#f = quimb.fidelity(peps_ccU.to_dense()[:, 0], sv)\n",
    "#print(\"ccU Fidelity after identity:\", f)  # Should be ≈1\n",
    "\n",
    "#np.linalg.norm(peps_ccU.overlap(peps_trotter))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a772f58-2869-4501-9726-44d5fd270915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16794142051915614"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for i in range(L):\n",
    "    s += np.abs(peps_trotter.compute_local_expectation({map_[i]: np.array([[1, 0], [0, -1]])}, max_bond=4))\n",
    "s/L\n",
    "\"TROTTER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "466b106a-8f3a-44df-8a9d-4407f10df532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1571179515612079"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for i in range(L):\n",
    "    s += np.abs(peps_ccU.compute_local_expectation({map_[i]: np.array([[1, 0], [0, -1]])}, max_bond=4))\n",
    "s/L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8360db2b-06e6-4cda-912a-64e28636ccbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EXACT'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for i in range(L):\n",
    "    s += np.abs(peps_trotter.compute_local_expectation({map_[i]: np.array([[1, 0], [0, -1]])}, max_bond=4))\n",
    "s/L\n",
    "\"EXACT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce8b83b8-ed2f-480c-97f1-585363e1dfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15386237414605158"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s/L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b386f4b6-a8ac-4da0-b8b2-333beb28affa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9967444224388"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.abs(0.153862374-0.1571179515612)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03143912-7b83-4b11-bfe5-d200a5b1d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9859209534808439"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.abs(0.153862374-0.16794142051915614)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4311235d-2266-42f6-85b7-3c045f91ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = []\n",
    "with h5py.File('peps_ccU_MOCK.h5', 'r') as f:\n",
    "    for key in sorted(f.keys(), key=lambda x: int(x.split('_')[1])):\n",
    "        data = np.array(f[key][:], dtype=np.float64)  # Force NumPy + valid dtype\n",
    "        inds = list(f[key].attrs['inds'])\n",
    "        tensors.append(qtn.Tensor(data=data, inds=inds))\n",
    "\n",
    "arrays = tuple(\n",
    "    tuple(tensors[i * Ly + j] for j in range(Ly))\n",
    "    for i in range(Lx)\n",
    ")\n",
    "\n",
    "peps_loaded = qtn.PEPS(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1595ad69-83db-4a43-9d1b-3e4f76130bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rqcopt as oc\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "I2 = np.eye(2)\n",
    "\n",
    "def trotter(peps, t, L, Lx, Ly, J, g, perms_v, perms_h, dag=False, max_bond_dim=5, \n",
    "            dt=0.1, trotter_order=2, treshold=10, lower_max_bond_dim=4):\n",
    "    nsteps = np.abs(int(np.ceil(t/dt)))\n",
    "    t = t/nsteps\n",
    "    indices = oc.SplittingMethod.suzuki(2, int(np.log(trotter_order)/np.log(2))).indices\n",
    "    coeffs = oc.SplittingMethod.suzuki(2, int(np.log(trotter_order)/np.log(2))).coeffs\n",
    "    \n",
    "    hloc1 = g*(np.kron(X, I2)+np.kron(I2, X))/4\n",
    "    hloc2 = J*np.kron(Z, Z)\n",
    "    hlocs = (hloc1, hloc2)\n",
    "    Vlist_start = []\n",
    "    for i, c in zip(indices, coeffs):\n",
    "        Vlist_start.append(-1j*c*t*hlocs[i])\n",
    "\n",
    "    for n in range(nsteps):\n",
    "        for layer, V in enumerate(Vlist_start):\n",
    "            i = n*len(Vlist_start)+layer\n",
    "            for perm in perms_h:\n",
    "                ordering = {(map_[perm[2*j]], map_[perm[2*j+1]]): V for j in range(L//2)}\n",
    "                start = time.time()\n",
    "                t = TEBD2D(peps, ham=LocalHam2D(Lx, Ly, ordering, cyclic=True),\n",
    "                    tau=-1, D=max_bond_dim if i<treshold else lower_max_bond_dim, chi=1)\n",
    "                t.sweep(tau=-1)\n",
    "                peps = t.state\n",
    "                \n",
    "            for perm in perms_v:\n",
    "                ordering = {(map_[perm[2*j]], map_[perm[2*j+1]]): V for j in range(L//2)}\n",
    "                start = time.time()\n",
    "                t = TEBD2D(peps, ham=LocalHam2D(Lx, Ly, ordering, cyclic=True),\n",
    "                    tau=-1, D=max_bond_dim if i<treshold else lower_max_bond_dim, chi=1)\n",
    "                t.sweep(tau=-1)\n",
    "                peps = t.state\n",
    "            #with open(f\"trotter_PEPS_log{Lx}{Ly}.txt\", \"a\") as file:\n",
    "            #    file.write(f\"Time step {n}/{nsteps}, layer {layer}/{len(Vlist_start)} applied \\n\")\n",
    "            print(f\"Time step {n}/{nsteps}, layer {layer}/{len(Vlist_start)} applied\")\n",
    "    print(f\"Norm. Trotter\")\n",
    "    peps.normalize()\n",
    "    print(f\"norm finished Trotter\")\n",
    "    return peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3546982-58c7-43a5-ba02-4f4b0ee80083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccU(peps, Vlist, perms_extended, control_layers, dagger=False, max_bond_dim=10, lower_max_bond_dim=4, treshold=10):\n",
    "    for i, V in enumerate(Vlist):\n",
    "        if dagger or i not in control_layers:\n",
    "            perms = perms_extended[i]\n",
    "            for perm in perms:\n",
    "                ordering = {(map_[perm[2*j]], map_[perm[2*j+1]]): scipy.linalg.logm(V) for j in range(L//2)}\n",
    "                start = time.time()\n",
    "                t = TEBD2D(peps, ham=LocalHam2D(Lx, Ly, ordering, cyclic=True),\n",
    "                    tau=-1, D=max_bond_dim if i<treshold else lower_max_bond_dim, chi=1)\n",
    "                t.sweep(tau=-1)\n",
    "                peps = t.state\n",
    "                #peps /= peps.norm()\n",
    "                print(f\"Step {i} took {time.time() - start:.2f} seconds\")\n",
    "                #print(\"Peak memory:\", tracemalloc.get_traced_memory())\n",
    "    print(f\"Normalize ccU\")\n",
    "    peps.normalize()\n",
    "    print(f\"Normalization of ccU finished\")\n",
    "    return peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579c5b1-714e-47fb-8b0d-ad42a31d4ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee8731-2099-4289-812d-8847dda92af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10cda94-3589-4500-9332-ffef8d50c402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (qc)",
   "language": "python",
   "name": "qc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
