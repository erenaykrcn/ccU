{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a8d76416-7262-40e0-ba50-6019ca349967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def left_normalize(Ms):\n",
    "    As = []\n",
    "    T = np.ones((1, 1))\n",
    "    for M in Ms:\n",
    "        M = np.tensordot(T, M, axes=(1, 1)) \n",
    "        M = np.transpose(M, [1, 0, 2])\n",
    "        d, chi1, chi2 = M.shape             \n",
    "        U, S, Vh = np.linalg.svd(np.reshape(M, [d*chi1, chi2]), full_matrices=False)\n",
    "        A = np.reshape(U, [d, chi1, -1])   \n",
    "        As.append(A)                        \n",
    "        T = np.diag(S) @ Vh                 \n",
    "\n",
    "    # Keep leftover signs (but no normalization)\n",
    "    As[0] = As[0]*np.sign(T)\n",
    "    return As\n",
    "\n",
    "def right_normalize(Ms):\n",
    "    Bs = []\n",
    "    T = np.ones((1, 1))\n",
    "    for M in Ms[::-1]:\n",
    "        M = np.tensordot(M, T, axes=(2, 0))\n",
    "        d, chi1, chi2 = M.shape\n",
    "        M = np.reshape(M, [chi1, d*chi2])\n",
    "        U, S, Vh = np.linalg.svd(M, full_matrices=False)\n",
    "        _, chi_s = U.shape\n",
    "        Bs.append(Vh.reshape([chi_s, d, chi2]).transpose([1, 0, 2]))\n",
    "        T = U@np.diag(S)\n",
    "    Bs[0] = Bs[0] * np.sign(T)\n",
    "    return Bs[::-1]\n",
    "\n",
    "    \n",
    "def random_mps(L_plus_1, max_bond_dim=None, anc=None):\n",
    "    D = max_bond_dim if max_bond_dim is not None else np.inf\n",
    "    \n",
    "    d = 2  # Qubit system (dim=2)\n",
    "    mps = []\n",
    "\n",
    "    D1 = min(D, d)\n",
    "    A0 = np.zeros((d, 1, D1), dtype=np.complex128)\n",
    "    if anc is None:\n",
    "        A0[0, 0, :] = np.random.randn(D1) + 1j * np.random.randn(D1)  # only |0⟩ component\n",
    "        A0[1, 0, :] = np.random.randn(D1) + 1j * np.random.randn(D1)  # only |0⟩ component\n",
    "    elif anc==0:\n",
    "        A0[0, 0, :] = np.random.randn(D1) + 1j * np.random.randn(D1)  # only |0⟩ component\n",
    "    else:\n",
    "        A0[1, 0, :] = np.random.randn(D1) + 1j * np.random.randn(D1)  # only |0⟩ component\n",
    "        \n",
    "    A0 /= np.linalg.norm(A0)  # normalize\n",
    "    mps.append(A0)\n",
    "        \n",
    "    Dl = D1\n",
    "    # Middle sites (1 to L-1)\n",
    "    for i in range(1, L_plus_1 - 1):\n",
    "        Dr = min(D, d * Dl)\n",
    "        A = np.random.randn(d, Dl, Dr) + 1j * np.random.randn(d, Dl, Dr)\n",
    "        A /= np.linalg.norm(A)\n",
    "        mps.append(A)\n",
    "        Dl = Dr\n",
    "\n",
    "    # Last site (site L): (d=2, Dl, Dr=1)\n",
    "    A_last = np.random.randn(d, Dl, 1) + 1j * np.random.randn(d, Dl, 1)\n",
    "    A_last /= np.linalg.norm(A_last)\n",
    "    mps.append(A_last)\n",
    "    mps = left_normalize(mps)\n",
    "    return mps\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "L_plus_1 = 13\n",
    "mps_tensors = random_mps(L_plus_1, max_bond_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "c578c1a8-ea66-4bce-b9ac-6aaf71cdff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mps_fidelity(mps1, mps2):\n",
    "    assert len(mps1) == len(mps2), \"MPSs must have same length\"\n",
    "\n",
    "    # Start with scalar \"environment\" = 1\n",
    "    env = np.ones((1, 1))  # shape (1, 1)\n",
    "    for A, B in zip(mps1, mps2):\n",
    "        env = np.tensordot(env, A, axes=(0, 1))\n",
    "        env = np.tensordot(env, B.conj(), axes=([0, 1], [1, 0]))\n",
    "    # env should now be scalar (1x1)\n",
    "    inner_product = env[0, 0]\n",
    "    fidelity = np.linalg.norm(inner_product) ** 2\n",
    "    return fidelity.real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d72940be-a9e5-4da4-97bd-69b3113a6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qiskit\n",
    "from qiskit.quantum_info import state_fidelity\n",
    "from numpy import linalg as LA\n",
    "import qib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import h5py\n",
    "from scipy.sparse.linalg import expm_multiply\n",
    "from qiskit.quantum_info import random_statevector\n",
    "from scipy.linalg import expm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../src/brickwall_sparse\")\n",
    "from utils_sparse import get_perms\n",
    "sys.path.append(\"../../src/MPS\")\n",
    "from utils_MPS import (random_mps, apply_localGate, apply_two_site_operator, \n",
    "\t\t\t\t\t\tmps_to_state_vector, get_mps_of_sv, mps_fidelity)\n",
    "from MPS import trotter, ccU\n",
    "\n",
    "Lx, Ly = (4, 4)\n",
    "L= Lx*Ly\n",
    "\n",
    "# construct Hamiltonian\n",
    "latt = qib.lattice.IntegerLattice((Lx, Ly), pbc=True)\n",
    "field = qib.field.Field(qib.field.ParticleType.QUBIT, latt)\n",
    "J, h, g = (1, 0, 3)\n",
    "hamil = qib.IsingHamiltonian(field, J, h, g).as_matrix()\n",
    "eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(hamil, k=10)\n",
    "idx = eigenvalues.argsort()\n",
    "eigenvalues_sort = eigenvalues[idx]\n",
    "eigenvectors_sort = eigenvectors[:,idx]\n",
    "ground_state = eigenvectors_sort[:, 0]\n",
    "\n",
    "perms_v, perms_h = get_perms(Lx, Ly)\n",
    "perms_extended = [[perms_v[0]]] + [perms_v]*3 + [[perms_v[0]], [perms_h[0]]] +\\\n",
    "                    [perms_h]*3 + [[perms_h[0]], [perms_v[0]]] + [perms_v]*3 + [[perms_v[0]]]\n",
    "perms_ext_reduced = [perms_v]*3  + [perms_h]*3 + [perms_v]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc76d0cf-8b1e-4770-8987-fcb7163c3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vlist = []\n",
    "with h5py.File(f\"./results/tfim2d_ccU_SPARSE_103_Lx4Ly4_t0.25_layers15_rS1_niter15_3hloc.hdf5\", \"r\") as f:\n",
    "    Vlist =  f[\"Vlist\"][:]\n",
    "    \n",
    "control_layers = [0, 4, 5, 9, 10, 14]\n",
    "perms_qc = [[0, 1], [0, 2], [1, 2], [0, 2], [0, 1], [1, 2], [0, 2], [0, 1], [1, 2]]\n",
    "Xlists_opt = {}\n",
    "for i in control_layers:\n",
    "    with h5py.File(f\"./results/tfim2d_ccU_SPARSE_103_Lx4Ly4_t0.25_layers15_niter20_rS5_DECOMPOSE_n9_layer{i}.hdf5\", \"r\") as file:\n",
    "        Xlists_opt[i] = file[f\"Xlist_{i}\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4baf772-0980-48ce-b258-0bf34367c8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'perms_v, perms_h = (\\n[[0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\\n [1, 2, 3, 4, 5, 0, 7, 8, 9, 10, 11, 6, 13, 14, 15, 16, 17, 12, 19, 20, 21, 22, 23, 18, 25, 26, 27, 28, 29, 24, 31, 32, 33, 34, 35, 30]],\\n[[0, 6, 12, 18, 24, 30, 1, 7, 13, 19, 25, 31, 2, 8, 14, 20, 26, 32, 3, 9, 15, 21, 27, 33, 4, 10, 16, 22, 28, 34, 5, 11, 17, 23, 29, 35], \\n [6, 12, 18, 24, 30, 0, 7, 13, 19, 25, 31, 1, 8, 14, 20, 26, 32, 2, 9, 15, 21, 27, 33, 3, 10, 16, 22, 28, 34, 4, 11, 17, 23, 29, 35, 5]]\\n )\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"perms_v, perms_h = (\n",
    "[[0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
    " [1, 2, 3, 4, 5, 0, 7, 8, 9, 10, 11, 6, 13, 14, 15, 16, 17, 12, 19, 20, 21, 22, 23, 18, 25, 26, 27, 28, 29, 24, 31, 32, 33, 34, 35, 30]],\n",
    "[[0, 6, 12, 18, 24, 30, 1, 7, 13, 19, 25, 31, 2, 8, 14, 20, 26, 32, 3, 9, 15, 21, 27, 33, 4, 10, 16, 22, 28, 34, 5, 11, 17, 23, 29, 35], \n",
    " [6, 12, 18, 24, 30, 0, 7, 13, 19, 25, 31, 1, 8, 14, 20, 26, 32, 2, 9, 15, 21, 27, 33, 3, 10, 16, 22, 28, 34, 4, 11, 17, 23, 29, 35, 5]]\n",
    " )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "682ecf0d-db71-4c95-9a05-39451c9aeff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt -0.125\n",
      "dt 0.08333333333333333\n",
      "ccU backwards fidelity:  0.9856362364497463\n",
      "ccU forwards fidelity:  0.9967732853692048\n"
     ]
    }
   ],
   "source": [
    "t     = 0.25\n",
    "dt    = 0.1\n",
    "order = 2\n",
    "initial_state_BD, exact_state_BD, ccU_BD = (2**2, 2**8, 2**8)\n",
    "\n",
    "\n",
    "initial_mps = random_mps(L, max_bond_dim=initial_state_BD)\n",
    "with h5py.File(f\"./MPS/tfim2d_Lx{Lx}Ly{Ly}__MPS_103_t0.25_INITIAL_MPS.h5\", \"w\") as f:\n",
    "    mps_group = f.create_group(\"mps\")\n",
    "    for i, tensor in enumerate(initial_mps):\n",
    "        mps_group.create_dataset(f\"site_{i}\", data=tensor)\n",
    "    f.attrs[\"L\"] = L\n",
    "    f.attrs[\"t\"] = float(t)\n",
    "with h5py.File(f\"./MPS/tfim2d_Lx{Lx}Ly{Ly}__MPS_103_t0.25_INITIAL_MPS.h5\", \"r\") as f:\n",
    "    mps_group = f[\"mps\"]\n",
    "    initial_mps = [mps_group[f\"site_{i}\"][()] for i in range(L)]\n",
    "\n",
    "\n",
    "exact_mps_back_input = initial_mps.copy()\n",
    "exact_mps_backwards = trotter(exact_mps_back_input, -t, L, Lx, Ly, J, g, max_bond_dim=exact_state_BD, trotter_order=order, dt=dt)\n",
    "with h5py.File(f\"./MPS/tfim2d_Lx{Lx}Ly{Ly}__MPS_103_t0.25_TROTTER_MPS_BACKWARDS_Order{order}_dt{dt}.h5\", \"w\") as f:\n",
    "    mps_group = f.create_group(\"mps\")\n",
    "    for i, tensor in enumerate(exact_mps_backwards):\n",
    "        mps_group.create_dataset(f\"site_{i}\", data=tensor)\n",
    "    f.attrs[\"L\"] = L\n",
    "    f.attrs[\"t\"] = float(t)\n",
    "    f.attrs[\"order\"] = order\n",
    "    f.attrs[\"dt\"] = dt\n",
    "with h5py.File(f\"./MPS/tfim2d_Lx{Lx}Ly{Ly}__MPS_103_t0.25_TROTTER_MPS_BACKWARDS_Order{order}_dt{dt}.h5\", \"r\") as f:\n",
    "    mps_group = f[\"mps\"]\n",
    "    exact_mps_backwards = [mps_group[f\"site_{i}\"][()] for i in range(L)]\n",
    "\n",
    "\n",
    "exact_mps_forw_input = initial_mps.copy()\n",
    "exact_mps_forwards = trotter(exact_mps_forw_input, t, L, Lx, Ly, J, g, max_bond_dim=exact_state_BD, trotter_order=order, dt=dt)\n",
    "with h5py.File(f\"./MPS/tfim2d_Lx{Lx}Ly{Ly}__MPS_103_t0.25_TROTTER_MPS_FORWARDS_Order{order}_dt{dt}.h5\", \"w\") as f:\n",
    "    mps_group = f.create_group(\"mps\")\n",
    "    for i, tensor in enumerate(exact_mps_forwards):\n",
    "        mps_group.create_dataset(f\"site_{i}\", data=tensor)\n",
    "    f.attrs[\"L\"] = L\n",
    "    f.attrs[\"t\"] = float(t)\n",
    "    f.attrs[\"order\"] = order\n",
    "    f.attrs[\"dt\"] = dt\n",
    "with h5py.File(f\"./MPS/tfim2d_Lx{Lx}Ly{Ly}__MPS_103_t0.25_TROTTER_MPS_FORWARDS_Order{order}_dt{dt}.h5\", \"r\") as f:\n",
    "    mps_group = f[\"mps\"]\n",
    "    exact_mps_forwards = [mps_group[f\"site_{i}\"][()] for i in range(L)]\n",
    "\n",
    "\n",
    "\n",
    "A0 = np.zeros((2, 1, 1), dtype=np.complex128)\n",
    "A0[0, :, :] = 1\n",
    "initial_mps_backwards = [A0]+initial_mps\n",
    "exact_mps_backwards_EXT = [A0]+exact_mps_backwards\n",
    "mps_ccU_backwards = ccU(initial_mps_backwards, L, Vlist, Xlists_opt, perms_extended, perms_qc, control_layers, max_bond_dim=ccU_BD)\n",
    "with h5py.File(f\"./MPS/tfim2d_Lx{Lx}Ly{Ly}__MPS_103_t0.25_ccU_MPS_BACKWARDS.h5\", \"w\") as f:\n",
    "    mps_group = f.create_group(\"mps\")\n",
    "    for i, tensor in enumerate(mps_ccU_backwards):\n",
    "        mps_group.create_dataset(f\"site_{i}\", data=tensor)\n",
    "    f.attrs[\"L\"] = L\n",
    "    f.attrs[\"t\"] = float(t)\n",
    "    f.attrs[\"order\"] = order\n",
    "    f.attrs[\"dt\"] = dt\n",
    "with h5py.File(f\"./MPS/tfim2d_Lx{Lx}Ly{Ly}__MPS_103_t0.25_ccU_MPS_BACKWARDS.h5\", \"r\") as f:\n",
    "    mps_group = f[\"mps\"]\n",
    "    mps_ccU_backwards = [mps_group[f\"site_{i}\"][()] for i in range(L+1)]\n",
    "print(\"ccU backwards fidelity: \", mps_fidelity(exact_mps_backwards_EXT, mps_ccU_backwards))\n",
    "\n",
    "\n",
    "\n",
    "A0 = np.zeros((2, 1, 1), dtype=np.complex128)\n",
    "A0[1, :, :] = 1\n",
    "initial_mps_forwards = [A0]+initial_mps\n",
    "exact_mps_forwards_EXT = [A0]+exact_mps_forwards\n",
    "mps_ccU_forwards = ccU(initial_mps_forwards, L, Vlist, Xlists_opt, perms_extended, perms_qc, control_layers, max_bond_dim=ccU_BD)\n",
    "with h5py.File(f\"./MPS/tfim2d_Lx{Lx}Ly{Ly}_MPS_103_t0.25_ccU_MPS_FORWARDS.h5\", \"w\") as f:\n",
    "    mps_group = f.create_group(\"mps\")\n",
    "    for i, tensor in enumerate(mps_ccU_forwards):\n",
    "        mps_group.create_dataset(f\"site_{i}\", data=tensor)\n",
    "    f.attrs[\"L\"] = L\n",
    "    f.attrs[\"t\"] = float(t)\n",
    "    f.attrs[\"order\"] = order\n",
    "    f.attrs[\"dt\"] = dt\n",
    "with h5py.File(f\"./MPS/tfim2d_Lx{Lx}Ly{Ly}_MPS_103_t0.25_ccU_MPS_FORWARDS.h5\", \"r\") as f:\n",
    "    mps_group = f[\"mps\"]\n",
    "    mps_ccU_forwards = [mps_group[f\"site_{i}\"][()] for i in range(L+1)]\n",
    "print(\"ccU forwards fidelity: \", mps_fidelity(exact_mps_forwards_EXT, mps_ccU_forwards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfa367-1630-4bb2-bb0a-3a181c1359f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0da84-36bc-4334-83a0-3df51dd9d965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72397902-2fe6-4fce-bfd0-119c1af447e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (qc)",
   "language": "python",
   "name": "qc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
