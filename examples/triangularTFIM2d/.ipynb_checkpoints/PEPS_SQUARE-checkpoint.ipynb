{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21bcf6e-50f3-4760-9840-51c9f194abd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhamil = qib.IsingHamiltonian(field, J, h, g).as_matrix()\\ndef eval_energy(config):\\n    e = 0\\n    for perm in perms_1+perms_2+perms_3:\\n        for j in range(len(perm)//2):\\n            e += 1 if config[perm[2*j]]==config[perm[2*j+1]] else -1\\n    return e\\ne = 48\\ngs = '0'*L\\ngss = []\\nbitstrings = [''.join(bits) for bits in product('01', repeat=16)]\\nfor bitstring in bitstrings:\\n    if eval_energy(bitstring) < e:\\n        gs = bitstring\\n        e = eval_energy(bitstring)\\n    if eval_energy(bitstring) == -16:\\n        gss.append(bitstring)\\nground_states = gss\\nn = len(ground_states[0])\\ndim = 2**n\\nstate = np.zeros(dim, dtype=complex)\\nfor s in ground_states:\\n    index = int(s, 2)\\n    state[index] = 1 / np.sqrt(len(ground_states))\\npsi = Statevector(state)\\n#eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(hamil, k=100)\\neigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(hamil, k=10, v0=psi.data, which='SA')\\nidx = eigenvalues.argsort()\\neigenvalues_sort = eigenvalues[idx]\\neigenvectors_sort = eigenvectors[:,idx]\\nground_state = eigenvectors_sort[:, 0]\\n\\neigenvalues_sort[0]\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import qiskit\n",
    "from qiskit.quantum_info import state_fidelity\n",
    "from numpy import linalg as LA\n",
    "import qib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import h5py\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../src/brickwall_sparse\")\n",
    "from utils_sparse import construct_ising_local_term, reduce_list, X, I2, get_perms\n",
    "from ansatz_sparse import ansatz_sparse\n",
    "import rqcopt as oc\n",
    "from scipy.sparse.linalg import expm_multiply\n",
    "from qiskit.quantum_info import random_statevector\n",
    "from scipy.linalg import expm\n",
    "from itertools import product\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector\n",
    "import time\n",
    "import tracemalloc\n",
    "tracemalloc.start()\n",
    "\n",
    "J, h, g = (1, 0, 3)\n",
    "Lx, Ly = (4, 4)\n",
    "L = Lx*Ly\n",
    "t = 0.125\n",
    "# construct Hamiltonian\n",
    "latt = qib.lattice.TriangularLattice((Lx, Ly), pbc=True)\n",
    "field = qib.field.Field(qib.field.ParticleType.QUBIT, latt)\n",
    "\n",
    "\n",
    "perms_1 = [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [1, 2, 3, 0, 5, 6, 7, 4, 9, 10, 11, 8, 13, 14, 15, 12]]\n",
    "perms_2 = [[0, 4, 8, 12, 1, 5, 9, 13, 2, 6, 10, 14, 3, 7, 11, 15], [4, 8, 12, 0, 5, 9, 13, 1, 6, 10, 14, 2, 7, 11, 15, 3]]\n",
    "perms_3 = [[0, 5, 10, 15, 3, 4, 9, 14, 2, 7, 8, 13, 1, 6, 11, 12], [5, 10, 15, 0, 4, 9, 14, 3, 7, 8, 13, 2, 6, 11, 12, 1]]\n",
    "\"\"\"\n",
    "hamil = qib.IsingHamiltonian(field, J, h, g).as_matrix()\n",
    "def eval_energy(config):\n",
    "    e = 0\n",
    "    for perm in perms_1+perms_2+perms_3:\n",
    "        for j in range(len(perm)//2):\n",
    "            e += 1 if config[perm[2*j]]==config[perm[2*j+1]] else -1\n",
    "    return e\n",
    "e = 48\n",
    "gs = '0'*L\n",
    "gss = []\n",
    "bitstrings = [''.join(bits) for bits in product('01', repeat=16)]\n",
    "for bitstring in bitstrings:\n",
    "    if eval_energy(bitstring) < e:\n",
    "        gs = bitstring\n",
    "        e = eval_energy(bitstring)\n",
    "    if eval_energy(bitstring) == -16:\n",
    "        gss.append(bitstring)\n",
    "ground_states = gss\n",
    "n = len(ground_states[0])\n",
    "dim = 2**n\n",
    "state = np.zeros(dim, dtype=complex)\n",
    "for s in ground_states:\n",
    "    index = int(s, 2)\n",
    "    state[index] = 1 / np.sqrt(len(ground_states))\n",
    "psi = Statevector(state)\n",
    "#eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(hamil, k=100)\n",
    "eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(hamil, k=10, v0=psi.data, which='SA')\n",
    "idx = eigenvalues.argsort()\n",
    "eigenvalues_sort = eigenvalues[idx]\n",
    "eigenvectors_sort = eigenvectors[:,idx]\n",
    "ground_state = eigenvectors_sort[:, 0]\n",
    "\n",
    "eigenvalues_sort[0]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf5945a-da44-4733-bfdc-597999dbb3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lx, Ly = (6, 6)\n",
    "L = Lx*Ly\n",
    "perms_1 = [[i for i in range(36)], \n",
    "           [1, 2, 3, 4, 5, 0,\n",
    "            7, 8, 9, 10, 11, 6,\n",
    "           13, 14, 15, 16, 17, 12, \n",
    "           19, 20, 21, 22, 23, 18,\n",
    "           25, 26, 27, 28, 29, 24,\n",
    "           31, 32, 33, 34, 35, 30]]\n",
    "perms_2 = [[0, 7, 14, 21, 28, 35, \n",
    "            1, 8, 15, 22, 29, 30, \n",
    "            2, 9, 16, 23, 24, 31, \n",
    "            3, 10, 17, 18, 25, 32, \n",
    "            4, 11, 12, 19, 26, 33, \n",
    "            5, 6, 13, 20, 27, 34], \n",
    "           [7, 14, 21, 28, 35, 0,\n",
    "           8, 15, 22, 29, 30, 1,\n",
    "           9, 16, 23, 24, 31, 2,\n",
    "           10, 17, 18, 25, 32, 3,\n",
    "           11, 12, 19, 26, 33, 4, \n",
    "           6, 13, 20, 27, 34, 5]]\n",
    "perms_3 = [[0, 6, 12, 18, 24, 30,\n",
    "            1, 7, 13, 19, 25, 31, \n",
    "            2, 8, 14, 20, 26, 32,\n",
    "            3, 9, 15, 21, 27, 33, \n",
    "            4, 10, 16, 22, 28, 34, \n",
    "            5, 11, 17, 23, 29, 35], \n",
    "           [6, 12, 18, 24, 30, 0,\n",
    "           7, 13, 19, 25, 31, 1,\n",
    "           8, 14, 20, 26, 32, 2,\n",
    "           9, 15, 21, 27, 33, 3, \n",
    "           10, 16, 22, 28, 34, 4, \n",
    "           11, 17, 23, 29, 35, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69f448c-8bb5-46c4-9c1f-caa1ad2c979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vlists = {}\n",
    "for t in [0.125]:\n",
    "    with h5py.File(f'./results/triangularTFIM_ccU_SPARSE_10{g}_Lx4Ly4_t{t}_layers9_niter10_rS1_2hloc.hdf5') as f:\n",
    "        Vlists[t]  =  f[\"Vlist\"][:]\n",
    "Vlist = Vlists[0.125]\n",
    "perms_extended = [[perms_1[0]]] + [perms_1] + [[perms_1[0]], [perms_2[0]]] +\\\n",
    "                    [perms_2] + [[perms_2[0]], [perms_3[0]]] + [perms_3] + [[perms_3[0]]] \n",
    "perms_ext_reduced = [perms_1]  + [perms_2] + [perms_3]\n",
    "control_layers = [0, 2, 3, 5, 6, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f98e424-0c50-44d7-b02f-f10c87eef713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m control_layers:\n\u001b[1;32m     10\u001b[0m         Vlist_reduced\u001b[38;5;241m.\u001b[39mappend(V)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfidelity: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m(state_fidelity(ansatz_sparse(Vlist, L, perms_extended, \u001b[43mstate\u001b[49m), expm_multiply(\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m t \u001b[38;5;241m*\u001b[39m hamil, state)) \u001b[38;5;241m+\u001b[39m state_fidelity(ansatz_sparse(Vlist_reduced, L, perms_ext_reduced, state), expm_multiply(\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m t \u001b[38;5;241m*\u001b[39m hamil, state)))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Test operations.\n",
    "\"\"\"\n",
    "\n",
    "for t in [0.125]:\n",
    "    Vlist = Vlists[t]\n",
    "    Vlist_reduced = []\n",
    "    for i, V in enumerate(Vlist):\n",
    "        if i not in control_layers:\n",
    "            Vlist_reduced.append(V)\n",
    "    \n",
    "    print('infidelity: ', 1-(state_fidelity(ansatz_sparse(Vlist, L, perms_extended, state), expm_multiply(\n",
    "        1j * t * hamil, state)) + state_fidelity(ansatz_sparse(Vlist_reduced, L, perms_ext_reduced, state), expm_multiply(\n",
    "        -1j * t * hamil, state)))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d1eb7aa-97ef-411f-909c-5ba9ce878d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import time\n",
    "import rqcopt as oc\n",
    "from quimb.tensor.tensor_arbgeom_tebd import LocalHamGen, TEBDGen, edge_coloring\n",
    "\n",
    "# Pauli and identity\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "I2 = np.eye(2)\n",
    "\n",
    "\n",
    "def layer_from_flat_perm(perm_row, L):\n",
    "    \"\"\"perm_row is a flat list of length L.\"\"\"\n",
    "    return [(perm_row[2*j], perm_row[2*j+1]) for j in range(L // 2)]\n",
    "layers_raw = [\n",
    "    perms_1[0], perms_1[1],\n",
    "    perms_2[0], perms_2[1],\n",
    "    perms_3[0], perms_3[1],\n",
    "]\n",
    "perms_for_trotter = [layer_from_flat_perm(row, L) for row in layers_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c1a6c0-c5fd-4197-b24f-b1912ad2eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quimb as qu\n",
    "import quimb.tensor as qtn\n",
    "\n",
    "\n",
    "def triangular_permutations(Lx, Ly):\n",
    "    \"\"\"\n",
    "    Return three nearest-neighbour permutation pairs for a PBC triangular lattice\n",
    "    on an Lx x Ly grid.\n",
    "\n",
    "    Each perms_k is [src_list, tgt_list], where src_list[i] -> tgt_list[i].\n",
    "\n",
    "    For Lx == Ly, this exactly reproduces your 4x4 perms_1, perms_2, perms_3\n",
    "    (up to the values of Lx, Ly).\n",
    "    \"\"\"\n",
    "    def idx(x, y):\n",
    "        # row-major site indexing: (x, y) -> i\n",
    "        return x * Ly + y\n",
    "\n",
    "    # --- perms_1: vertical neighbours (x, y) -> (x, y+1) ---\n",
    "    p1_src, p1_tgt = [], []\n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            p1_src.append(idx(x, y))\n",
    "            p1_tgt.append(idx(x, (y + 1) % Ly))\n",
    "\n",
    "    # --- perms_2: diagonal neighbours (x, y) -> (x+1, y+1) ---\n",
    "    p2_src, p2_tgt = [], []\n",
    "    if Lx == Ly:\n",
    "        # match your 4x4 pattern exactly, generalized to L=Lx=Ly\n",
    "        L = Lx\n",
    "        # order offsets by 0, L-1, L-2, ..., 1\n",
    "        offsets = [0] + list(reversed(range(1, L)))\n",
    "        for off in offsets:\n",
    "            for x in range(L):\n",
    "                y = (x + off) % L\n",
    "                p2_src.append(idx(x, y))\n",
    "                p2_tgt.append(idx((x + 1) % L, (y + 1) % L))\n",
    "    else:\n",
    "        # simple, consistent ordering for rectangular case\n",
    "        for x in range(Lx):\n",
    "            for y in range(Ly):\n",
    "                p2_src.append(idx(x, y))\n",
    "                p2_tgt.append(idx((x + 1) % Lx, (y + 1) % Ly))\n",
    "\n",
    "    # --- perms_3: horizontal neighbours (x, y) -> (x+1, y) ---\n",
    "    # loop over y then x so that for Lx == Ly we reproduce your 4x4 perms_3.\n",
    "    p3_src, p3_tgt = [], []\n",
    "    for y in range(Ly):\n",
    "        for x in range(Lx):\n",
    "            p3_src.append(idx(x, y))\n",
    "            p3_tgt.append(idx((x + 1) % Lx, y))\n",
    "\n",
    "    perms_1 = [p1_src, p1_tgt]\n",
    "    perms_2 = [p2_src, p2_tgt]\n",
    "    perms_3 = [p3_src, p3_tgt]\n",
    "\n",
    "    return perms_1, perms_2, perms_3\n",
    "\n",
    "\n",
    "\n",
    "def _edges_from_permutations(perms_1, perms_2, perms_3):\n",
    "    \"\"\"\n",
    "    Take the three [src, tgt] permutation pairs and return a sorted list of\n",
    "    unique undirected edges (i, j) with i < j.\n",
    "    \"\"\"\n",
    "    edge_set = set()\n",
    "\n",
    "    for perms in (perms_1, perms_2, perms_3):\n",
    "        src, tgt = perms\n",
    "        for a, b in zip(src, tgt):\n",
    "            if a == b:\n",
    "                continue\n",
    "            i, j = sorted((a, b))\n",
    "            edge_set.add((i, j))\n",
    "\n",
    "    return sorted(edge_set)\n",
    "\n",
    "\n",
    "def build_triangular_PEPS(Lx, Ly, bond_dim, phys_dim=2,\n",
    "                          seed=None, dtype=\"complex128\"):\n",
    "    edges = _edges_from_permutations(perms_1, perms_2, perms_3)\n",
    "    tn = qtn.TN_from_edges_rand(\n",
    "        edges,\n",
    "        D=bond_dim,\n",
    "        phys_dim=phys_dim,\n",
    "        seed=seed,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "    return tn, (perms_1, perms_2, perms_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86051313-811e-48b4-9e4c-6404aaaf3fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "def trotter(peps, t, L, Lx, Ly, J, g, perms, dag=False,\n",
    "                      max_bond_dim=5, dt=0.1, trotter_order=2):\n",
    "    # Number of steps\n",
    "    nsteps = abs(int(np.ceil(t / dt)))\n",
    "    dt = t / nsteps\n",
    "\n",
    "    # Suzuki splitting\n",
    "    if trotter_order > 1:\n",
    "        sm = oc.SplittingMethod.suzuki(2, int(np.log(trotter_order)/np.log(2)))\n",
    "        indices, coeffs = sm.indices, sm.coeffs\n",
    "    else:\n",
    "        indices, coeffs = [0, 1], [1, 1]\n",
    "\n",
    "    \n",
    "    hloc1 = g*(np.kron(X, I2)+np.kron(I2, X))/6\n",
    "    hloc2 = J*np.kron(Z, Z)\n",
    "    hlocs = (hloc1, hloc2)\n",
    "    Vlist_start = []\n",
    "    for i, c in zip(indices, coeffs):\n",
    "        Vlist_start.append(-1j*c*dt*hlocs[i])\n",
    "\n",
    "    for n in range(nsteps):\n",
    "        for layer, V in enumerate(Vlist_start):\n",
    "            i = n*len(Vlist_start)+layer\n",
    "            for perm in perms:\n",
    "                #ordering = {(perm[2*j], perm[2*j+1]): V for j in range(L//2)}\n",
    "                #start = time.time()\n",
    "                \n",
    "                ordering = {(map_[perm[2*j]], map_[perm[2*j+1]]): V for j in range(L//2)}\n",
    "                tebd = TEBD2D(peps, ham=LocalHam2D(Lx, Ly, ordering, cyclic=True),\n",
    "                    tau=-1, D=max_bond_dim, chi=1)\n",
    "                tebd.sweep(tau=-1)\n",
    "                peps = tebd.state\n",
    "\n",
    "                del tebd\n",
    "                gc.collect()\n",
    "    return peps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669b4011-c156-4535-9fd1-70fb6e0a730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccU(peps, Vlist, perms_extended, control_layers, dagger=False, max_bond_dim=10):\n",
    "    for i, V in enumerate(Vlist):\n",
    "        if dagger or i not in control_layers:\n",
    "            perms = perms_extended[i]\n",
    "            for perm in perms:\n",
    "                ordering = {(map_[perm[2*j]], map_[perm[2*j+1]]): scipy.linalg.logm(V) for j in range(L//2)}\n",
    "                t = TEBD2D(peps, ham=LocalHam2D(Lx, Ly, ordering, cyclic=True),\n",
    "                    tau=-1, D=max_bond_dim, chi=1)\n",
    "                t.sweep(tau=-1)\n",
    "                peps = t.state\n",
    "                \n",
    "                del t\n",
    "                gc.collect()\n",
    "    return peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212acb5a-c9e5-4dd6-b92e-1e91ad0ce432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:36: UserWarning: Couldn't import `kahypar` - skipping from default hyper optimizer and using basic `labels` method instead. `kahypar` is highly recommended for the best quality contraction paths.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/quimb/tensor/tensor_core.py:8584: UserWarning: The contraction tree is not a compressed one, this may be very inefficient.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import quimb as qu\n",
    "import quimb.tensor as qtn\n",
    "\n",
    "chi_overlap = 10  # max internal bond during compressed contraction\n",
    "peps = qtn.PEPS.rand(Lx, Ly, bond_dim=1, phys_dim=2, cyclic=True)\n",
    "\n",
    "peps_copy_norm = peps.copy()\n",
    "ov_tn = peps_copy_norm.make_overlap(\n",
    "    peps_copy_norm,\n",
    "    layer_tags=(\"KET\", \"BRA\"),\n",
    ")\n",
    "overlap_approx = ov_tn.contract_compressed(\n",
    "    optimize=\"auto-hq\",\n",
    "    max_bond=chi_overlap,\n",
    "    cutoff=1e-10,\n",
    ")\n",
    "norm = np.sqrt(abs(overlap_approx))\n",
    "peps = peps/np.abs(norm)\n",
    "\n",
    "ov_tn = peps.make_overlap(\n",
    "    peps,\n",
    "    layer_tags=(\"KET\", \"BRA\"),\n",
    ")\n",
    "overlap_approx = ov_tn.contract_compressed(\n",
    "    optimize=\"auto-hq\",\n",
    "    max_bond=chi_overlap,\n",
    "    cutoff=1e-10,\n",
    ")\n",
    "print(np.abs(overlap_approx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a2259-dc36-481c-adb7-53ef62eb9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.quantum_info import state_fidelity\n",
    "import quimb.tensor as qtn\n",
    "import quimb\n",
    "from quimb.tensor.tensor_2d_tebd import TEBD2D, LocalHam2D\n",
    "\n",
    "peps_E = peps.copy()\n",
    "peps_T = peps.copy()\n",
    "peps_C = peps.copy()\n",
    "\n",
    "map_ = {i: (i//Ly, i%Lx) for i in range(L)}\n",
    "BD = 3\n",
    "nsteps = 1\n",
    "peps_E = trotter(peps_E.copy(), t, L, Lx, Ly, J, g, perms_1+perms_2+perms_3,\n",
    "                     dt=t/nsteps, max_bond_dim=BD, trotter_order=2)\n",
    "peps_aE = ccU(peps_C.copy(), Vlist, perms_extended, control_layers, dagger=False,\n",
    "                 max_bond_dim=BD)\n",
    "peps_T = trotter(peps_T.copy(), t, L, Lx, Ly, J, g, perms_1+perms_2+perms_3,\n",
    "                     dt=t/nsteps, max_bond_dim=BD, trotter_order=1)\n",
    "\n",
    "#peps_T.compress_all(max_bond=BD)\n",
    "#peps_E.compress_all(max_bond=BD)\n",
    "#peps_aE.compress_all(max_bond=BD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8345a-6ec6-42fd-85ee-8b1484471d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ov_tn = peps_E.make_overlap(\n",
    "    peps_aE,\n",
    "    layer_tags=(\"KET\", \"BRA\"),\n",
    ")\n",
    "\n",
    "chi_overlap = 5  # max internal bond during compressed contraction\n",
    "overlap_approx = ov_tn.contract_compressed(\n",
    "    optimize=\"auto-hq\",\n",
    "    max_bond=chi_overlap,\n",
    "    cutoff=1e-10,\n",
    ")\n",
    "\n",
    "np.abs(overlap_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d84f4cc6-b3a6-46ba-b4f1-39de2512a5fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/quimb/tensor/tensor_core.py:8584: UserWarning: The contraction tree is not a compressed one, this may be very inefficient.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9142700143479502"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ov_tn = peps_E.make_overlap(\n",
    "    peps_T,\n",
    "    layer_tags=(\"KET\", \"BRA\"),\n",
    ")\n",
    "\n",
    "chi_overlap = 5  # max internal bond during compressed contraction\n",
    "overlap_approx = ov_tn.contract_compressed(\n",
    "    optimize=\"auto-hq\",  # preset strategy name understood via cotengra\n",
    "    max_bond=chi_overlap,\n",
    "    cutoff=1e-10,\n",
    "    # leave strip_exponent=False (default) so we just get a scalar back\n",
    ")\n",
    "\n",
    "np.abs(overlap_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2577180e-61d3-46b6-8ce0-b77a69ab68c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: not enough values to unpack (expected 2, got 1). Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: not enough values to unpack (expected 2, got 1). Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: No module named 'kahypar'. Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: No module named 'kahypar'. Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: not enough values to unpack (expected 2, got 1). Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: not enough values to unpack (expected 2, got 1). Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: No module named 'kahypar'. Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: No module named 'kahypar'. Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: No module named 'kahypar'. Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: not enough values to unpack (expected 2, got 1). Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: not enough values to unpack (expected 2, got 1). Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: No module named 'kahypar'. Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: not enough values to unpack (expected 2, got 1). Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: not enough values to unpack (expected 2, got 1). Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/qc/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:329: UserWarning: Trial error: not enough values to unpack (expected 2, got 1). Set `HyperOptimizer` kwarg `on_trial_error='raise'` to raise this error, or `on_trial_error='ignore'` to silence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "k, l = (0, 1)\n",
    "\n",
    "phys_k = f'k{k}'\n",
    "phys_l = f'k{l}'\n",
    "bra = peps_E.conj(mangle_inner=True)\n",
    "bra_k = f'{phys_k}_BRA'\n",
    "bra_l = f'{phys_l}_BRA'\n",
    "bra = bra.reindex({phys_k: bra_k, phys_l: bra_l})\n",
    "ov_tn = bra & peps_T\n",
    "out_inds = (bra_k, bra_l, phys_k, phys_l)\n",
    "\n",
    "T = ov_tn.contract_compressed(\n",
    "        output_inds=out_inds,\n",
    "        optimize=\"hyper-compressed\",\n",
    "        max_bond=chi_overlap,\n",
    "        cutoff=1e-10,\n",
    ")\n",
    "\n",
    "A = np.asarray(T.data).reshape(2, 2, 2, 2)\n",
    "M = A.reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0583e-ca9d-4d84-8961-d151a0ee41cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32031b-3eeb-4215-9edb-1483c3a87703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a39ecc42-f24d-4f3d-b602-5dd64b629191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1add128-f63f-41fa-a4a0-c4a31d122772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (qc)",
   "language": "python",
   "name": "qc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
